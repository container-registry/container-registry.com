{
    "chart_count": 0,
    "creation_time": "2024-09-10 03:38:36.774000+00:00",
    "current_user_role_id": 1,
    "current_user_role_ids": [
        1
    ],
    "cve_allowlist": {
        "creation_time": "0001-01-01 00:00:00+00:00",
        "expires_at": null,
        "id": 34,
        "items": [],
        "project_id": 34,
        "update_time": "0001-01-01 00:00:00+00:00"
    },
    "deleted": null,
    "metadata": {
        "auto_scan": null,
        "enable_content_trust": null,
        "enable_content_trust_cosign": null,
        "instance": "centred_ramanujan",
        "instanceUrl": "https://centred-ramanujan.container-registry.com",
        "monthlyPrice": 10900,
        "monthlyPriceId": "price_1PxhyTDmAMB1YDyjDCyKKFAg",
        "oneTimePrice": 9900,
        "oneTimePriceId": "price_1PxgzgDmAMB1YDyjMeJmdaev",
        "prevent_vul": null,
        "public": "false",
        "retention_id": null,
        "reuse_sys_cve_allowlist": null,
        "severity": null
    },
    "name": "ai",
    "owner_id": 1,
    "owner_name": "admin",
    "project_id": 34,
    "registry_id": null,
    "repo_count": 5,
    "repositories": [
        {
            "artifact_count": 1,
            "artifacts": [
                {
                    "accessories": null,
                    "addition_links": {
                        "build_history": {
                            "absolute": false,
                            "href": "/api/v2.0/projects/ai/repositories/qdrant/artifacts/sha256:8c69f10655519f1392826aec4fe6f94f68146980429d7c7e1c4f78c1dd9c3c77/additions/build_history"
                        },
                        "vulnerabilities": {
                            "absolute": false,
                            "href": "/api/v2.0/projects/ai/repositories/qdrant/artifacts/sha256:8c69f10655519f1392826aec4fe6f94f68146980429d7c7e1c4f78c1dd9c3c77/additions/vulnerabilities"
                        }
                    },
                    "annotations": null,
                    "digest": "sha256:8c69f10655519f1392826aec4fe6f94f68146980429d7c7e1c4f78c1dd9c3c77",
                    "extra_attrs": {
                        "architecture": "amd64",
                        "author": "",
                        "config": {
                            "ArgsEscaped": true,
                            "Cmd": [
                                "./entrypoint.sh"
                            ],
                            "Env": [
                                "PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
                                "DIR=",
                                "TZ=Etc/UTC",
                                "RUN_MODE=production"
                            ],
                            "ExposedPorts": {
                                "6333/tcp": {},
                                "6334/tcp": {}
                            },
                            "Labels": {
                                "org.opencontainers.image.description": "Official Qdrant image",
                                "org.opencontainers.image.documentation": "https://qdrant.com/docs",
                                "org.opencontainers.image.source": "https://github.com/qdrant/qdrant",
                                "org.opencontainers.image.title": "Qdrant",
                                "org.opencontainers.image.url": "https://qdrant.com/",
                                "org.opencontainers.image.vendor": "Qdrant",
                                "org.opencontainers.image.version": "v1.11.3"
                            },
                            "User": "0:0",
                            "WorkingDir": "/qdrant"
                        },
                        "created": "2024-08-29T15:01:56.533132853Z",
                        "os": "linux"
                    },
                    "icon": "sha256:0048162a053eef4d4ce3fe7518615bef084403614f8bca43b40ae2e762e11e06",
                    "id": 43,
                    "labels": null,
                    "manifest_media_type": "application/vnd.oci.image.manifest.v1+json",
                    "media_type": "application/vnd.oci.image.config.v1+json",
                    "project_id": 34,
                    "pull_time": "2024-09-10 08:03:39.702000+00:00",
                    "push_time": "2024-09-10 07:52:22.101000+00:00",
                    "references": null,
                    "repository_id": 43,
                    "scan_overview": null,
                    "size": 81020835,
                    "tags": [
                        {
                            "artifact_id": 43,
                            "id": 43,
                            "immutable": false,
                            "name": "latest",
                            "pull_time": "2024-09-10 08:03:39.702000+00:00",
                            "push_time": "2024-09-10 07:52:22.419000+00:00",
                            "repository_id": 43,
                            "signed": false
                        }
                    ],
                    "type": "IMAGE"
                }
            ],
            "build_history": [
                {
                    "created": "2024-08-13T00:20:20.12417704Z",
                    "created_by": "/bin/sh -c #(nop) ADD file:3d9897cfe027ecc7cbdb16e74a676ed143725ea2d08dbb0dde23309e041de0f3 in / "
                },
                {
                    "created": "2024-08-13T00:20:20.441291951Z",
                    "created_by": "/bin/sh -c #(nop)  CMD [\"bash\"]",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-29T14:15:44.873210166Z",
                    "created_by": "RUN /bin/sh -c apt-get update # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-29T14:15:58.374065157Z",
                    "created_by": "ARG PACKAGES",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-29T14:15:58.374065157Z",
                    "created_by": "RUN |1 PACKAGES= /bin/sh -c apt-get install -y --no-install-recommends ca-certificates tzdata libunwind8 $PACKAGES     && rm -rf /var/lib/apt/lists/* # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-29T14:15:58.374065157Z",
                    "created_by": "ARG SOURCES",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-29T14:15:58.374065157Z",
                    "created_by": "ENV DIR=",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-29T15:01:52.360940812Z",
                    "created_by": "COPY /null? / # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-29T15:01:52.360940812Z",
                    "created_by": "ENV DIR=",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-29T15:01:53.225363993Z",
                    "created_by": "COPY /null? / # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-29T15:01:53.225363993Z",
                    "created_by": "ENV DIR=",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-29T15:01:54.115459494Z",
                    "created_by": "COPY /null? / # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-29T15:01:54.115459494Z",
                    "created_by": "ENV DIR=",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-29T15:01:55.006133004Z",
                    "created_by": "COPY /null? / # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-29T15:01:55.006133004Z",
                    "created_by": "ENV DIR=",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-29T15:01:55.006133004Z",
                    "created_by": "ARG APP=/qdrant",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-29T15:01:55.798537303Z",
                    "created_by": "COPY /qdrant/qdrant /qdrant/qdrant # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-29T15:01:55.950029588Z",
                    "created_by": "COPY /qdrant/config /qdrant/config # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-29T15:01:56.086920434Z",
                    "created_by": "COPY /qdrant/tools/entrypoint.sh /qdrant/entrypoint.sh # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-29T15:01:56.244902525Z",
                    "created_by": "COPY /static /qdrant/static # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-29T15:01:56.359387503Z",
                    "created_by": "WORKDIR /qdrant"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-29T15:01:56.359387503Z",
                    "created_by": "ARG USER_ID=0",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-29T15:01:56.533132853Z",
                    "created_by": "RUN |4 PACKAGES= SOURCES= APP=/qdrant USER_ID=0 /bin/sh -c if [ \"$USER_ID\" != 0 ]; then         groupadd --gid \"$USER_ID\" qdrant;         useradd --uid \"$USER_ID\" --gid \"$USER_ID\" -m qdrant;         mkdir -p \"$APP\"/storage \"$APP\"/snapshots;         chown -R \"$USER_ID:$USER_ID\" \"$APP\";     fi # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-29T15:01:56.533132853Z",
                    "created_by": "USER 0:0",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-29T15:01:56.533132853Z",
                    "created_by": "ENV TZ=Etc/UTC RUN_MODE=production",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-29T15:01:56.533132853Z",
                    "created_by": "EXPOSE map[6333/tcp:{}]",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-29T15:01:56.533132853Z",
                    "created_by": "EXPOSE map[6334/tcp:{}]",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-29T15:01:56.533132853Z",
                    "created_by": "LABEL org.opencontainers.image.title=Qdrant",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-29T15:01:56.533132853Z",
                    "created_by": "LABEL org.opencontainers.image.description=Official Qdrant image",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-29T15:01:56.533132853Z",
                    "created_by": "LABEL org.opencontainers.image.url=https://qdrant.com/",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-29T15:01:56.533132853Z",
                    "created_by": "LABEL org.opencontainers.image.documentation=https://qdrant.com/docs",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-29T15:01:56.533132853Z",
                    "created_by": "LABEL org.opencontainers.image.source=https://github.com/qdrant/qdrant",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-29T15:01:56.533132853Z",
                    "created_by": "LABEL org.opencontainers.image.vendor=Qdrant",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-29T15:01:56.533132853Z",
                    "created_by": "CMD [\"./entrypoint.sh\"]",
                    "empty_layer": true
                }
            ],
            "creation_time": "2024-09-10 07:52:21.828000+00:00",
            "description": "[author]: <> (Qdrant)\n[shortDescription]: <> (Qdrant - High-performance, massive-scale Vector Database for the next generation of AI. Also available in the cloud https://cloud.qdrant.io/)\n[subTitle]: <> (High-Performance Vector Search at Scale)\n\n<p align=\"center\">\n  <img height=\"100\" src=\"https://github.com/qdrant/qdrant/raw/master/docs/logo.svg\" alt=\"Qdrant\">\n</p>\n\n<p align=\"center\">\n    <b>Vector Search Engine for the next generation of AI applications</b>\n</p>\n\n<p align=center>\n    <a href=\"https://github.com/qdrant/qdrant/actions/workflows/rust.yml\"><img src=\"https://img.shields.io/github/actions/workflow/status/qdrant/qdrant/rust.yml?style=flat-square\" alt=\"Tests status\"></a>\n    <a href=\"https://api.qdrant.tech/\"><img src=\"https://img.shields.io/badge/Docs-OpenAPI%203.0-success?style=flat-square\" alt=\"OpenAPI Docs\"></a>\n    <a href=\"https://github.com/qdrant/qdrant/blob/master/LICENSE\"><img src=\"https://img.shields.io/github/license/qdrant/qdrant?style=flat-square\" alt=\"Apache 2.0 License\"></a>\n    <a href=\"https://qdrant.to/discord\"><img src=\"https://img.shields.io/discord/907569970500743200?logo=Discord&style=flat-square&color=7289da\" alt=\"Discord\"></a>\n    <a href=\"https://qdrant.to/roadmap\"><img src=\"https://img.shields.io/badge/Roadmap-2024-bc1439.svg?style=flat-square\" alt=\"Roadmap 2024\"></a>\n    <a href=\"https://cloud.qdrant.io/\"><img src=\"https://img.shields.io/badge/Qdrant-Cloud-24386C.svg?logo=cloud&style=flat-square\" alt=\"Qdrant Cloud\"></a>\n</p>\n\n**Qdrant** (read: _quadrant_) is a vector similarity search engine and vector database.\nIt provides a production-ready service with a convenient API to store, search, and manage points\u2014vectors with an additional payload\nQdrant is tailored to extended filtering support. It makes it useful for all sorts of neural-network or semantic-based matching, faceted search, and other applications.\n\nQdrant is written in Rust \ud83e\udd80, which makes it fast and reliable even under high load. See [benchmarks](https://qdrant.tech/benchmarks/).\n\nWith Qdrant, embeddings or neural network encoders can be turned into full-fledged applications for matching, searching, recommending, and much more!\n\nQdrant is also available as a fully managed **[Qdrant Cloud](https://cloud.qdrant.io/)** \u26c5 including a **free tier**.\n\n<p align=\"center\">\n<strong><a href=\"docs/QUICK_START.md\">Quick Start</a> \u2022 <a href=\"#clients\">Client Libraries</a> \u2022 <a href=\"#demo-projects\">Demo Projects</a> \u2022 <a href=\"#integrations\">Integrations</a> \u2022 <a href=\"#contacts\">Contact</a>\n\n</strong>\n</p>\n\n## Getting Started\n\n### Python\n\n```\npip install qdrant-client\n```\n\nThe python client offers a convenient way to start with Qdrant locally:\n\n```python\nfrom qdrant_client import QdrantClient\nqdrant = QdrantClient(\":memory:\") # Create in-memory Qdrant instance, for testing, CI/CD\n# OR\nclient = QdrantClient(path=\"path/to/db\")  # Persists changes to disk, fast prototyping\n```\n\n### Client-Server\n\nTo experience the full power of Qdrant locally, run the container with this command:\n\n```bash\ndocker run -p 6333:6333 qdrant/qdrant\n```\n\nNow you can connect to this with any client, including Python:\n\n```python\nqdrant = QdrantClient(\"http://localhost:6333\") # Connect to existing Qdrant instance\n```\n\nBefore deploying Qdrant to production, be sure to read our [installation](https://qdrant.tech/documentation/guides/installation/) and [security](https://qdrant.tech/documentation/guides/security/) guides.\n\n### Clients\n\nQdrant offers the following client libraries to help you integrate it into your application stack with ease:\n\n- Official:\n  - [Go client](https://github.com/qdrant/go-client)\n  - [Rust client](https://github.com/qdrant/rust-client)\n  - [JavaScript/TypeScript client](https://github.com/qdrant/qdrant-js)\n  - [Python client](https://github.com/qdrant/qdrant-client)\n  - [.NET/C# client](https://github.com/qdrant/qdrant-dotnet)\n  - [Java client](https://github.com/qdrant/java-client)\n- Community:\n  - [Elixir](https://hexdocs.pm/qdrant/readme.html)\n  - [PHP](https://github.com/hkulekci/qdrant-php)\n  - [Ruby](https://github.com/andreibondarev/qdrant-ruby)\n  - [Java](https://github.com/metaloom/qdrant-java-client)\n\n### Where do I go from here?\n\n- [Quick Start Guide](docs/QUICK_START.md)\n- End to End [Colab Notebook](https://colab.research.google.com/drive/1Bz8RSVHwnNDaNtDwotfPj0w7AYzsdXZ-?usp=sharing) demo with SentenceBERT and Qdrant\n- Detailed [Documentation](https://qdrant.tech/documentation/) are great starting points\n- [Step-by-Step Tutorial](https://qdrant.to/qdrant-tutorial) to create your first neural network project with Qdrant\n\n## Demo Projects  <a href=\"https://replit.com/@qdrant\"><img align=\"right\" src=\"https://replit.com/badge/github/qdrant/qdrant\" alt=\"Run on Repl.it\"></a>\n\n### Discover Semantic Text Search \ud83d\udd0d\n\nUnlock the power of semantic embeddings with Qdrant, transcending keyword-based search to find meaningful connections in short texts. Deploy a neural search in minutes using a pre-trained neural network, and experience the future of text search. [Try it online!](https://qdrant.to/semantic-search-demo)\n\n### Explore Similar Image Search - Food Discovery \ud83c\udf55\n\nThere's more to discovery than text search, especially when it comes to food. People often choose meals based on appearance rather than descriptions and ingredients. Let Qdrant help your users find their next delicious meal using visual search, even if they don't know the dish's name. [Check it out!](https://qdrant.to/food-discovery)\n\n### Master Extreme Classification - E-commerce Product Categorization \ud83d\udcfa\n\nEnter the cutting-edge realm of extreme classification, an emerging machine learning field tackling multi-class and multi-label problems with millions of labels. Harness the potential of similarity learning models, and see how a pre-trained transformer model and Qdrant can revolutionize e-commerce product categorization. [Play with it online!](https://qdrant.to/extreme-classification-demo)\n\n<details>\n<summary> More solutions </summary>\n\n<table>\n    <tr>\n        <td width=\"30%\">\n            <img src=\"https://qdrant.tech/content/images/text_search.png\">\n        </td>\n        <td width=\"30%\">\n            <img src=\"https://qdrant.tech/content/images/image_search.png\">\n        </td>\n        <td width=\"30%\">\n            <img src=\"https://qdrant.tech/content/images/recommendations.png\">\n        </td>\n    </tr>\n    <tr>\n        <td>\n            Semantic Text Search\n        </td>\n        <td>\n            Similar Image Search\n        </td>\n        <td>\n            Recommendations\n        </td>\n    </tr>\n</table>\n\n<table>\n    <tr>\n        <td>\n            <img width=\"300px\" src=\"https://qdrant.tech/content/images/chat_bots.png\">\n        </td>\n        <td>\n            <img width=\"300px\" src=\"https://qdrant.tech/content/images/matching_engines.png\">\n        </td>\n        <td>\n            <img width=\"300px\" src=\"https://qdrant.tech/content/images/anomalies_detection.png\">\n        </td>\n    </tr>\n    <tr>\n        <td>\n            Chat Bots\n        </td>\n        <td>\n            Matching Engines\n        </td>\n        <td>\n            Anomaly Detection\n        </td>\n    </tr>\n</table>\n\n</details>\n\n## API\n\n### REST\n\nOnline OpenAPI 3.0 documentation is available [here](https://api.qdrant.tech/).\nOpenAPI makes it easy to generate a client for virtually any framework or programming language.\n\nYou can also download raw OpenAPI [definitions](https://github.com/qdrant/qdrant/blob/master/docs/redoc/master/openapi.json).\n\n### gRPC\n\nFor faster production-tier searches, Qdrant also provides a gRPC interface. You can find gRPC documentation [here](https://qdrant.tech/documentation/quick-start/#grpc).\n\n## Features\n\n### Filtering and Payload\n\nQdrant can attach any JSON payloads to vectors, allowing for both the storage and filtering of data based on the values in these payloads.\nPayload supports a wide range of data types and query conditions, including keyword matching, full-text filtering, numerical ranges, geo-locations, and more.\n\nFiltering conditions can be combined in various ways, including `should`, `must`, and `must_not` clauses,\nensuring that you can implement any desired business logic on top of similarity matching.\n\n\n### Hybrid Search with Sparse Vectors\n\nTo address the limitations of vector embeddings when searching for specific keywords, Qdrant introduces support for sparse vectors in addition to the regular dense ones.\n\nSparse vectors can be viewed as an generalisation of BM25 or TF-IDF ranking. They enable you to harness the capabilities of transformer-based neural networks to weigh individual tokens effectively.\n\n\n### Vector Quantization and On-Disk Storage\n\nQdrant provides multiple options to make vector search cheaper and more resource-efficient.\nBuilt-in vector quantization reduces RAM usage by up to 97% and dynamically manages the trade-off between search speed and precision.\n\n\n### Distributed Deployment\n\nQdrant offers comprehensive horizontal scaling support through two key mechanisms:\n1. Size expansion via sharding and throughput enhancement via replication\n2. Zero-downtime rolling updates and seamless dynamic scaling of the collections\n\n\n### Highlighted Features\n\n* **Query Planning and Payload Indexes** - leverages stored payload information to optimize query execution strategy.\n* **SIMD Hardware Acceleration** - utilizes modern CPU x86-x64 and Neon architectures to deliver better performance.\n* **Async I/O** - uses `io_uring` to maximize disk throughput utilization even on a network-attached storage.\n* **Write-Ahead Logging** - ensures data persistence with update confirmation, even during power outages.\n\n\n# Integrations\n\nExamples and/or documentation of Qdrant integrations:\n\n- [Cohere](https://docs.cohere.com/docs/qdrant-and-cohere) ([blogpost on building a QA app with Cohere and Qdrant](https://qdrant.tech/articles/qa-with-cohere-and-qdrant/)) - Use Cohere embeddings with Qdrant\n- [DocArray](https://docs.docarray.org/user_guide/storing/index_qdrant/) - Use Qdrant as a document store in DocArray\n- [Haystack](https://haystack.deepset.ai/integrations/qdrant-document-store) - Use Qdrant as a document store with Haystack ([blogpost](https://haystack.deepset.ai/blog/qdrant-integration)).\n- [LangChain](https://python.langchain.com/docs/integrations/providers/qdrant/) ([blogpost](https://qdrant.tech/articles/langchain-integration/)) - Use Qdrant as a memory backend for LangChain.\n- [LlamaIndex](https://gpt-index.readthedocs.io/en/latest/examples/vector_stores/QdrantIndexDemo.html) - Use Qdrant as a Vector Store with LlamaIndex.\n- [OpenAI - ChatGPT retrieval plugin](https://github.com/openai/chatgpt-retrieval-plugin/blob/main/docs/providers/qdrant/setup.md) - Use Qdrant as a memory backend for ChatGPT\n- [Microsoft Semantic Kernel](https://devblogs.microsoft.com/semantic-kernel/the-power-of-persistent-memory-with-semantic-kernel-and-qdrant-vector-database/) - Use Qdrant as persistent memory with Semantic Kernel\n\n## Contacts\n\n- Have questions? Join our [Discord channel](https://qdrant.to/discord) or mention [@qdrant_engine on Twitter](https://qdrant.to/twitter)\n- Want to stay in touch with latest releases? Subscribe to our [Newsletters](https://qdrant.to/newsletter)\n- Looking for a managed cloud? Check [pricing](https://qdrant.tech/pricing/), need something personalised? We're at [info@qdrant.tech](mailto:info@qdrant.tech)\n\n## Contributors \u2728\n\nThanks to the people who contributed to Qdrant:\n\n<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->\n<!-- prettier-ignore-start -->\n<!-- markdownlint-disable -->\n<table>\n  <tbody>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://t.me/neural_network_engineering\"><img src=\"https://avatars.githubusercontent.com/u/1935623?v=4?s=50\" width=\"50px;\" alt=\"Andrey Vasnetsov\"/><br /><sub><b>Andrey Vasnetsov</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=generall\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/azayarni\"><img src=\"https://avatars.githubusercontent.com/u/926368?v=4?s=50\" width=\"50px;\" alt=\"Andre Zayarni\"/><br /><sub><b>Andre Zayarni</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=azayarni\" title=\"Documentation\">\ud83d\udcd6</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.linkedin.com/in/joanfontanalsmartinez/\"><img src=\"https://avatars.githubusercontent.com/u/19825685?v=4?s=50\" width=\"50px;\" alt=\"Joan Fontanals\"/><br /><sub><b>Joan Fontanals</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=JoanFM\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/trean\"><img src=\"https://avatars.githubusercontent.com/u/7085263?v=4?s=50\" width=\"50px;\" alt=\"trean\"/><br /><sub><b>trean</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=trean\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/kgrech\"><img src=\"https://avatars.githubusercontent.com/u/9020133?v=4?s=50\" width=\"50px;\" alt=\"Konstantin\"/><br /><sub><b>Konstantin</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=kgrech\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/kekonen\"><img src=\"https://avatars.githubusercontent.com/u/11177808?v=4?s=50\" width=\"50px;\" alt=\"Daniil Naumetc\"/><br /><sub><b>Daniil Naumetc</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=kekonen\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://dev.to/vearutop\"><img src=\"https://avatars.githubusercontent.com/u/1381436?v=4?s=50\" width=\"50px;\" alt=\"Viacheslav Poturaev\"/><br /><sub><b>Viacheslav Poturaev</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=vearutop\" title=\"Documentation\">\ud83d\udcd6</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/galibey\"><img src=\"https://avatars.githubusercontent.com/u/48586936?v=4?s=50\" width=\"50px;\" alt=\"Alexander Galibey\"/><br /><sub><b>Alexander Galibey</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=galibey\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/HaiCheViet\"><img src=\"https://avatars.githubusercontent.com/u/37202591?v=4?s=50\" width=\"50px;\" alt=\"HaiCheViet\"/><br /><sub><b>HaiCheViet</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=HaiCheViet\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://tranzystorek-io.github.io/\"><img src=\"https://avatars.githubusercontent.com/u/5671049?v=4?s=50\" width=\"50px;\" alt=\"Marcin Puc\"/><br /><sub><b>Marcin Puc</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=tranzystorek-io\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/anveq\"><img src=\"https://avatars.githubusercontent.com/u/94402218?v=4?s=50\" width=\"50px;\" alt=\"Anton V.\"/><br /><sub><b>Anton V.</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=anveq\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://agourlay.github.io\"><img src=\"https://avatars.githubusercontent.com/u/606963?v=4?s=50\" width=\"50px;\" alt=\"Arnaud Gourlay\"/><br /><sub><b>Arnaud Gourlay</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=agourlay\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://t.me/type_driven_thoughts\"><img src=\"https://avatars.githubusercontent.com/u/17401538?v=4?s=50\" width=\"50px;\" alt=\"Egor Ivkov\"/><br /><sub><b>Egor Ivkov</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=eadventurous\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/IvanPleshkov\"><img src=\"https://avatars.githubusercontent.com/u/20946825?v=4?s=50\" width=\"50px;\" alt=\"Ivan Pleshkov\"/><br /><sub><b>Ivan Pleshkov</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=IvanPleshkov\" title=\"Code\">\ud83d\udcbb</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/daniilsunyaev\"><img src=\"https://avatars.githubusercontent.com/u/3955599?v=4?s=50\" width=\"50px;\" alt=\"Daniil\"/><br /><sub><b>Daniil</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=daniilsunyaev\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://homeonrails.com\"><img src=\"https://avatars.githubusercontent.com/u/1282182?v=4?s=50\" width=\"50px;\" alt=\"Anton Kaliaev\"/><br /><sub><b>Anton Kaliaev</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=melekes\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://soundcloud.com/norom\"><img src=\"https://avatars.githubusercontent.com/u/7762532?v=4?s=50\" width=\"50px;\" alt=\"Andre Julius\"/><br /><sub><b>Andre Julius</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=NotNorom\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/prok20\"><img src=\"https://avatars.githubusercontent.com/u/20628026?v=4?s=50\" width=\"50px;\" alt=\"Prokudin Alexander\"/><br /><sub><b>Prokudin Alexander</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=prok20\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/elbart\"><img src=\"https://avatars.githubusercontent.com/u/48974?v=4?s=50\" width=\"50px;\" alt=\"Tim Eggert\"/><br /><sub><b>Tim Eggert</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=elbart\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/gvelo\"><img src=\"https://avatars.githubusercontent.com/u/943360?v=4?s=50\" width=\"50px;\" alt=\"Gabriel Velo\"/><br /><sub><b>Gabriel Velo</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=gvelo\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://burtonqin.github.io\"><img src=\"https://avatars.githubusercontent.com/u/11943383?v=4?s=50\" width=\"50px;\" alt=\"Boqin Qin(\u79e6 \u4f2f\u94a6)\"/><br /><sub><b>Boqin Qin(\u79e6 \u4f2f\u94a6)</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/issues?q=author%3ABurtonQin\" title=\"Bug reports\">\ud83d\udc1b</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://forloop.co.uk/blog\"><img src=\"https://avatars.githubusercontent.com/u/208231?v=4?s=50\" width=\"50px;\" alt=\"Russ Cam\"/><br /><sub><b>Russ Cam</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=russcam\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/erare-humanum\"><img src=\"https://avatars.githubusercontent.com/u/116254494?v=4?s=50\" width=\"50px;\" alt=\"erare-humanum\"/><br /><sub><b>erare-humanum</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=erare-humanum\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ffuugoo\"><img src=\"https://avatars.githubusercontent.com/u/2725918?v=4?s=50\" width=\"50px;\" alt=\"Roman Titov\"/><br /><sub><b>Roman Titov</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=ffuugoo\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://hozan23.com\"><img src=\"https://avatars.githubusercontent.com/u/119854621?v=4?s=50\" width=\"50px;\" alt=\"Hozan\"/><br /><sub><b>Hozan</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=hozan23\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/joein\"><img src=\"https://avatars.githubusercontent.com/u/22641570?v=4?s=50\" width=\"50px;\" alt=\"George\"/><br /><sub><b>George</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=joein\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/csko\"><img src=\"https://avatars.githubusercontent.com/u/749306?v=4?s=50\" width=\"50px;\" alt=\"Korn\u00e9l Csernai\"/><br /><sub><b>Korn\u00e9l Csernai</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=csko\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://coszio.github.io\"><img src=\"https://avatars.githubusercontent.com/u/62079184?v=4?s=50\" width=\"50px;\" alt=\"Luis Coss\u00edo\"/><br /><sub><b>Luis Coss\u00edo</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=coszio\" title=\"Code\">\ud83d\udcbb</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://timvisee.com/\"><img src=\"https://avatars.githubusercontent.com/u/856222?v=4?s=50\" width=\"50px;\" alt=\"Tim Vis\u00e9e\"/><br /><sub><b>Tim Vis\u00e9e</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=timvisee\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.timonv.nl\"><img src=\"https://avatars.githubusercontent.com/u/49373?v=4?s=50\" width=\"50px;\" alt=\"Timon Vonk\"/><br /><sub><b>Timon Vonk</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=timonv\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://loudcoder.com\"><img src=\"https://avatars.githubusercontent.com/u/12176046?v=4?s=50\" width=\"50px;\" alt=\"Yiping Deng\"/><br /><sub><b>Yiping Deng</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=DengYiping\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://weijun-h.github.io/\"><img src=\"https://avatars.githubusercontent.com/u/20267695?v=4?s=50\" width=\"50px;\" alt=\"Alex Huang\"/><br /><sub><b>Alex Huang</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=Weijun-H\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ibrahim-akrab\"><img src=\"https://avatars.githubusercontent.com/u/30220322?v=4?s=50\" width=\"50px;\" alt=\"Ibrahim M. Akrab\"/><br /><sub><b>Ibrahim M. Akrab</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=ibrahim-akrab\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/stencillogic\"><img src=\"https://avatars.githubusercontent.com/u/59373360?v=4?s=50\" width=\"50px;\" alt=\"stencillogic\"/><br /><sub><b>stencillogic</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=stencillogic\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/moaz-mokhtar\"><img src=\"https://avatars.githubusercontent.com/u/5870208?v=4?s=50\" width=\"50px;\" alt=\"Moaz bin Mokhtar\"/><br /><sub><b>Moaz bin Mokhtar</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=moaz-mokhtar\" title=\"Documentation\">\ud83d\udcd6</a></td>\n    </tr>\n  </tbody>\n</table>\n\n<!-- markdownlint-restore -->\n<!-- prettier-ignore-end -->\n\n<!-- ALL-CONTRIBUTORS-LIST:END -->\n\n## License\n\nQdrant is licensed under the Apache License, Version 2.0. View a copy of the [License file](https://github.com/qdrant/qdrant/blob/master/LICENSE).\n",
            "id": 43,
            "metadata": {
                "author": "Qdrant",
                "shortDescription": "Qdrant - High-performance, massive-scale Vector Database for the next generation of AI. Also available in the cloud https://cloud.qdrant.io/",
                "subTitle": "High-Performance Vector Search at Scale"
            },
            "name": "ai/qdrant",
            "project_id": 34,
            "pull_count": 1,
            "update_time": "2024-09-13 03:30:19.516000+00:00"
        },
        {
            "artifact_count": 1,
            "artifacts": [
                {
                    "accessories": null,
                    "addition_links": {
                        "build_history": {
                            "absolute": false,
                            "href": "/api/v2.0/projects/ai/repositories/openplayground/artifacts/sha256:d2b0c13ab73b64616237ba788f95de3bedef1fb7f8a82a3384590295eff7aa58/additions/build_history"
                        },
                        "vulnerabilities": {
                            "absolute": false,
                            "href": "/api/v2.0/projects/ai/repositories/openplayground/artifacts/sha256:d2b0c13ab73b64616237ba788f95de3bedef1fb7f8a82a3384590295eff7aa58/additions/vulnerabilities"
                        }
                    },
                    "annotations": null,
                    "digest": "sha256:d2b0c13ab73b64616237ba788f95de3bedef1fb7f8a82a3384590295eff7aa58",
                    "extra_attrs": {
                        "architecture": "amd64",
                        "author": "",
                        "config": {
                            "Entrypoint": [
                                "openplayground",
                                "run",
                                "--host",
                                "0.0.0.0",
                                "--env",
                                "/web/config/.env"
                            ],
                            "Env": [
                                "PATH=/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
                                "NVIDIA_VISIBLE_DEVICES=all",
                                "NVIDIA_DRIVER_CAPABILITIES=compute,utility",
                                "LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64",
                                "PYTORCH_VERSION=v2.0.0",
                                "PYTHONDONTWRITEBYTECODE=1",
                                "PYTHONUNBUFFERED=1",
                                "XDG_CONFIG_HOME=/web/config"
                            ],
                            "Labels": {
                                "com.nvidia.volumes.needed": "nvidia_driver",
                                "org.opencontainers.image.ref.name": "ubuntu",
                                "org.opencontainers.image.version": "18.04"
                            },
                            "WorkingDir": "/web/"
                        },
                        "created": "2023-04-05T12:37:49.377340529-07:00",
                        "os": "linux"
                    },
                    "icon": "sha256:0048162a053eef4d4ce3fe7518615bef084403614f8bca43b40ae2e762e11e06",
                    "id": 42,
                    "labels": null,
                    "manifest_media_type": "application/vnd.docker.distribution.manifest.v2+json",
                    "media_type": "application/vnd.docker.container.image.v1+json",
                    "project_id": 34,
                    "pull_time": "2024-09-10 08:02:54.314000+00:00",
                    "push_time": "2024-09-10 04:43:08.015000+00:00",
                    "references": null,
                    "repository_id": 42,
                    "scan_overview": null,
                    "size": 3528014043,
                    "tags": [
                        {
                            "artifact_id": 42,
                            "id": 42,
                            "immutable": false,
                            "name": "latest",
                            "pull_time": "2024-09-10 08:02:54.314000+00:00",
                            "push_time": "2024-09-10 04:43:08.340000+00:00",
                            "repository_id": 42,
                            "signed": false
                        }
                    ],
                    "type": "IMAGE"
                }
            ],
            "build_history": [
                {
                    "created": "2023-03-08T03:22:42.455864719Z",
                    "created_by": "/bin/sh -c #(nop)  ARG RELEASE",
                    "empty_layer": true
                },
                {
                    "created": "2023-03-08T03:22:42.517845487Z",
                    "created_by": "/bin/sh -c #(nop)  ARG LAUNCHPAD_BUILD_ARCH",
                    "empty_layer": true
                },
                {
                    "created": "2023-03-08T03:22:42.579821915Z",
                    "created_by": "/bin/sh -c #(nop)  LABEL org.opencontainers.image.ref.name=ubuntu",
                    "empty_layer": true
                },
                {
                    "created": "2023-03-08T03:22:42.646372194Z",
                    "created_by": "/bin/sh -c #(nop)  LABEL org.opencontainers.image.version=18.04",
                    "empty_layer": true
                },
                {
                    "created": "2023-03-08T03:22:44.482610627Z",
                    "created_by": "/bin/sh -c #(nop) ADD file:4560926e076acae6b8396a9f1e760eee0f53e22e90ce8554dda57f1103547795 in / "
                },
                {
                    "created": "2023-03-08T03:22:44.73196058Z",
                    "created_by": "/bin/sh -c #(nop)  CMD [\"/bin/bash\"]",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2023-03-20T11:09:34.414329098-07:00",
                    "created_by": "ARG PYTORCH_VERSION",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2023-03-20T11:09:34.414329098-07:00",
                    "created_by": "ARG TRITON_VERSION",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2023-03-20T11:09:34.414329098-07:00",
                    "created_by": "ARG TARGETPLATFORM",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2023-03-20T11:09:34.414329098-07:00",
                    "created_by": "ARG CUDA_VERSION",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2023-03-20T11:09:34.414329098-07:00",
                    "created_by": "LABEL com.nvidia.volumes.needed=nvidia_driver",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2023-03-20T11:09:34.414329098-07:00",
                    "created_by": "RUN |4 PYTORCH_VERSION=v2.0.0 TRITON_VERSION= TARGETPLATFORM=linux/amd64 CUDA_VERSION=11.7.0 /bin/sh -c apt-get update && apt-get install -y --no-install-recommends         ca-certificates         libjpeg-dev         libpng-dev # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2023-03-20T11:14:38.086570753-07:00",
                    "created_by": "COPY /opt/conda /opt/conda # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2023-03-20T11:14:38.887996315-07:00",
                    "created_by": "RUN |4 PYTORCH_VERSION=v2.0.0 TRITON_VERSION= TARGETPLATFORM=linux/amd64 CUDA_VERSION=11.7.0 /bin/sh -c if test -n \"${TRITON_VERSION}\" -a \"${TARGETPLATFORM}\" != \"linux/arm64\"; then         apt install -y --no-install-recommends gcc;     fi # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2023-03-20T11:14:39.348020993-07:00",
                    "created_by": "RUN |4 PYTORCH_VERSION=v2.0.0 TRITON_VERSION= TARGETPLATFORM=linux/amd64 CUDA_VERSION=11.7.0 /bin/sh -c rm -rf /var/lib/apt/lists/* # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2023-03-20T11:14:39.348020993-07:00",
                    "created_by": "ENV PATH=/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2023-03-20T11:14:39.348020993-07:00",
                    "created_by": "ENV NVIDIA_VISIBLE_DEVICES=all",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2023-03-20T11:14:39.348020993-07:00",
                    "created_by": "ENV NVIDIA_DRIVER_CAPABILITIES=compute,utility",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2023-03-20T11:14:39.348020993-07:00",
                    "created_by": "ENV LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2023-03-20T11:14:39.348020993-07:00",
                    "created_by": "ENV PYTORCH_VERSION=v2.0.0",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2023-03-20T11:14:39.467705773-07:00",
                    "created_by": "WORKDIR /workspace"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2023-04-05T10:47:28.842757598-07:00",
                    "created_by": "WORKDIR /web/"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2023-04-05T10:47:31.044723242-07:00",
                    "created_by": "ENV PYTHONDONTWRITEBYTECODE=1",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2023-04-05T10:47:31.044723242-07:00",
                    "created_by": "ENV PYTHONUNBUFFERED=1",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2023-04-05T10:47:31.044723242-07:00",
                    "created_by": "ENV XDG_CONFIG_HOME=/web/config",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2023-04-05T10:47:31.044723242-07:00",
                    "created_by": "ARG POETRY_VERSION=1.4.1",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2023-04-05T10:47:31.044723242-07:00",
                    "created_by": "RUN |1 POETRY_VERSION=1.4.1 /bin/sh -c pip install --no-cache-dir --upgrade pip # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2023-04-05T10:47:37.834994829-07:00",
                    "created_by": "RUN |1 POETRY_VERSION=1.4.1 /bin/sh -c pip install poetry==${POETRY_VERSION} # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2023-04-05T10:47:38.789603699-07:00",
                    "created_by": "RUN |1 POETRY_VERSION=1.4.1 /bin/sh -c poetry config virtualenvs.create false # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2023-04-05T12:37:13.276335887-07:00",
                    "created_by": "COPY server/ ./server/ # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2023-04-05T12:37:13.310356158-07:00",
                    "created_by": "COPY README.md . # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2023-04-05T12:37:37.832381202-07:00",
                    "created_by": "COPY /frontend/dist ./server/static/ # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2023-04-05T12:37:37.858748125-07:00",
                    "created_by": "COPY pyproject.toml . # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2023-04-05T12:37:37.895768208-07:00",
                    "created_by": "COPY poetry.lock . # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2023-04-05T12:37:49.377340529-07:00",
                    "created_by": "RUN |1 POETRY_VERSION=1.4.1 /bin/sh -c poetry install --without=dev --no-interaction --no-ansi # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2023-04-05T12:37:49.377340529-07:00",
                    "created_by": "ENTRYPOINT [\"openplayground\" \"run\" \"--host\" \"0.0.0.0\" \"--env\" \"/web/config/.env\"]",
                    "empty_layer": true
                }
            ],
            "creation_time": "2024-09-10 04:43:07.734000+00:00",
            "description": "[author]: <> (Nat Friedman)\n[shortDescription]: <> (An LLM playground you can run on your laptop)\n\n# openplayground\n\nAn LLM playground you can run on your laptop.\n\nhttps://user-images.githubusercontent.com/111631/227399583-39b23f48-9823-4571-a906-985dbe282b20.mp4\n\n#### Features\n\n- Use any model from [OpenAI](https://openai.com), [Anthropic](https://anthropic.com), [Cohere](https://cohere.com), [Forefront](https://forefront.ai), [HuggingFace](https://huggingface.co), [Aleph Alpha](https://aleph-alpha.com), [Replicate](https://replicate.com), [Banana](https://banana.dev) and [llama.cpp](https://github.com/ggerganov/llama.cpp).\n- Full playground UI, including history, parameter tuning, keyboard shortcuts, and logprops.\n- Compare models side-by-side with the same prompt, individually tune model parameters, and retry with different parameters.\n- Automatically detects local models in your HuggingFace cache, and lets you install new ones.\n- Works OK on your phone.\n- Probably won't kill everyone.\n\n## Try on nat.dev\n\nTry the hosted version: [nat.dev](https://nat.dev).\n\n## How to install and run\n\n```sh\npip install openplayground\nopenplayground run\n```\n\nAlternatively, run it as a docker container:\n```sh\ndocker run --name openplayground -p 5432:5432 -d --volume openplayground:/web/config natorg/openplayground\n```\n\nThis runs a Flask process, so you can add the typical flags such as setting a different port `openplayground run -p 1235` and others.\n\n## How to run for development\n\n```sh\ngit clone https://github.com/nat/openplayground\ncd app && npm install && npx parcel watch src/index.html --no-cache\ncd server && pip3 install -r requirements.txt && cd .. && python3 -m server.app\n```\n\n## Docker\n\n```sh\ndocker build . --tag \"openplayground\"\ndocker run --name openplayground -p 5432:5432 -d --volume openplayground:/web/config openplayground\n```\n\nFirst volume is optional. It's used to store API keys, models settings.\n\n## Ideas for contributions\n\n- Add a token counter to the playground\n- Add a cost counter to the playground and the compare page\n- Measure and display time to first token\n- Setup automatic builds with GitHub Actions\n- The default parameters for each model are configured in the `server/models.json` file. If you find better default parameters for a model, please submit a pull request!\n- Someone can help us make a homebrew package, and a dockerfile\n- Easier way to install open source models directly from openplayground, with `openplayground install <model>` or in the UI.\n- Find and fix bugs\n- ChatGPT UI, with turn-by-turn, markdown rendering, chatgpt plugin support, etc.\n- We will probably need multimodal inputs and outputs at some point in 2023\n\n### llama.cpp\n\n## Adding models to openplayground\n\nModels and providers have three types in openplayground:\n\n- Searchable\n- Local inference\n- API\n\nYou can add models in `server/models.json` with the following schema:\n\n#### Local inference\n\nFor models running locally on your device you can add them to openplayground like the following (a minimal example):\n\n```json\n\"llama\": {\n    \"api_key\" : false,\n    \"models\" : {\n        \"llama-70b\": {\n            \"parameters\": {\n                \"temperature\": {\n                    \"value\": 0.5,\n                    \"range\": [\n                        0.1,\n                        1.0\n                    ]\n                },\n            }\n        }\n    }\n}\n```\n\nKeep in mind you will need to add a generation method for your model in `server/app.py`. Take a look at `local_text_generation()` as an example.\n\n#### API Provider Inference\n\nThis is for model providers like OpenAI, cohere, forefront, and more. You can connect them easily into openplayground (a minimal example):\n\n```json\n\"cohere\": {\n    \"api_key\" : true,\n    \"models\" : {\n        \"xlarge\": {\n            \"parameters\": {\n                \"temperature\": {\n                    \"value\": 0.5,\n                    \"range\": [\n                        0.1,\n                        1.0\n                    ]\n                },\n            }\n        }\n    }\n}\n```\n\nKeep in mind you will need to add a generation method for your model in `server/app.py`. Take a look at `openai_text_generation()` or `cohere_text_generation()` as an example.\n\n#### Searchable models\n\nWe use this for Huggingface Remote Inference models, the search endpoint is useful for scaling to N models in the settings page.\n\n```json\n\"provider_name\": {\n    \"api_key\": true,\n    \"search\": {\n        \"endpoint\": \"ENDPOINT_URL\"\n    },\n    \"parameters\": {\n        \"parameter\": {\n            \"value\": 1.0,\n            \"range\": [\n                0.1,\n                1.0\n            ]\n        },\n    }\n}\n```\n\n#### Credits\n\nInstigated by Nat Friedman. Initial implementation by [Zain Huda](https://github.com/zainhuda) as a repl.it bounty. Many features and extensive refactoring by [Alex Lourenco](https://github.com/AlexanderLourenco).\n",
            "id": 42,
            "metadata": {
                "author": "Nat Friedman",
                "shortDescription": "An LLM playground you can run on your laptop"
            },
            "name": "ai/openplayground",
            "project_id": 34,
            "pull_count": 1,
            "update_time": "2024-09-13 03:33:00.350000+00:00"
        },
        {
            "artifact_count": 1,
            "artifacts": [
                {
                    "accessories": null,
                    "addition_links": {
                        "build_history": {
                            "absolute": false,
                            "href": "/api/v2.0/projects/ai/repositories/localai/artifacts/sha256:658bd196803f18a6d053bf16d56af15aeda35669f8721641dbfb3d85d2564e2d/additions/build_history"
                        },
                        "vulnerabilities": {
                            "absolute": false,
                            "href": "/api/v2.0/projects/ai/repositories/localai/artifacts/sha256:658bd196803f18a6d053bf16d56af15aeda35669f8721641dbfb3d85d2564e2d/additions/vulnerabilities"
                        }
                    },
                    "annotations": null,
                    "digest": "sha256:658bd196803f18a6d053bf16d56af15aeda35669f8721641dbfb3d85d2564e2d",
                    "extra_attrs": {
                        "architecture": "amd64",
                        "author": "",
                        "config": {
                            "Entrypoint": [
                                "/aio/entrypoint.sh"
                            ],
                            "Env": [
                                "PATH=/opt/rocm/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/root/go/bin:/usr/local/go/bin",
                                "DEBIAN_FRONTEND=noninteractive",
                                "EXTERNAL_GRPC_BACKENDS=coqui:/build/backend/python/coqui/run.sh,huggingface-embeddings:/build/backend/python/sentencetransformers/run.sh,transformers:/build/backend/python/transformers/run.sh,sentencetransformers:/build/backend/python/sentencetransformers/run.sh,rerankers:/build/backend/python/rerankers/run.sh,autogptq:/build/backend/python/autogptq/run.sh,bark:/build/backend/python/bark/run.sh,diffusers:/build/backend/python/diffusers/run.sh,exllama:/build/backend/python/exllama/run.sh,openvoice:/build/backend/python/openvoice/run.sh,vall-e-x:/build/backend/python/vall-e-x/run.sh,vllm:/build/backend/python/vllm/run.sh,mamba:/build/backend/python/mamba/run.sh,exllama2:/build/backend/python/exllama2/run.sh,transformers-musicgen:/build/backend/python/transformers-musicgen/run.sh,parler-tts:/build/backend/python/parler-tts/run.sh",
                                "BUILD_TYPE=",
                                "REBUILD=false",
                                "HEALTHCHECK_ENDPOINT=http://localhost:8080/readyz",
                                "MAKEFLAGS=--jobs=4 --output-sync=target",
                                "NVIDIA_DRIVER_CAPABILITIES=compute,utility",
                                "NVIDIA_REQUIRE_CUDA=cuda>=.0",
                                "NVIDIA_VISIBLE_DEVICES=all"
                            ],
                            "ExposedPorts": {
                                "8080/tcp": {}
                            },
                            "Labels": {
                                "org.opencontainers.image.created": "2024-08-23T08:30:43.700Z",
                                "org.opencontainers.image.description": ":robot: The free, Open Source alternative to OpenAI, Claude and others. Self-hosted and local-first. Drop-in replacement for OpenAI,  running on consumer-grade hardware. No GPU required. Runs gguf, transformers, diffusers and many more models architectures. Features: Generate Text, Audio, Video, Images, Voice Cloning, Distributed inference",
                                "org.opencontainers.image.licenses": "MIT",
                                "org.opencontainers.image.ref.name": "ubuntu",
                                "org.opencontainers.image.revision": "a9c521eb41dc2dd63769e5362f05d9ab5d8bec50",
                                "org.opencontainers.image.source": "https://github.com/mudler/LocalAI",
                                "org.opencontainers.image.title": "LocalAI",
                                "org.opencontainers.image.url": "https://github.com/mudler/LocalAI",
                                "org.opencontainers.image.version": "v2.20.1-aio-cpu"
                            },
                            "User": "root",
                            "Volumes": {
                                "/build/models": {}
                            },
                            "WorkingDir": "/build"
                        },
                        "created": "2024-08-23T10:57:42.822902737Z",
                        "os": "linux"
                    },
                    "icon": "sha256:0048162a053eef4d4ce3fe7518615bef084403614f8bca43b40ae2e762e11e06",
                    "id": 41,
                    "labels": null,
                    "manifest_media_type": "application/vnd.docker.distribution.manifest.v2+json",
                    "media_type": "application/vnd.docker.container.image.v1+json",
                    "project_id": 34,
                    "pull_time": "2024-09-10 10:33:04.944000+00:00",
                    "push_time": "2024-09-10 04:29:13.137000+00:00",
                    "references": null,
                    "repository_id": 41,
                    "scan_overview": null,
                    "size": 2205762362,
                    "tags": [
                        {
                            "artifact_id": 41,
                            "id": 41,
                            "immutable": false,
                            "name": "latest",
                            "pull_time": "2024-09-10 10:33:04.944000+00:00",
                            "push_time": "2024-09-10 04:29:13.461000+00:00",
                            "repository_id": 41,
                            "signed": false
                        }
                    ],
                    "type": "IMAGE"
                }
            ],
            "build_history": [
                {
                    "created": "2024-08-13T09:27:22.357288914Z",
                    "created_by": "/bin/sh -c #(nop)  ARG RELEASE",
                    "empty_layer": true
                },
                {
                    "created": "2024-08-13T09:27:22.382523486Z",
                    "created_by": "/bin/sh -c #(nop)  ARG LAUNCHPAD_BUILD_ARCH",
                    "empty_layer": true
                },
                {
                    "created": "2024-08-13T09:27:22.406703187Z",
                    "created_by": "/bin/sh -c #(nop)  LABEL org.opencontainers.image.ref.name=ubuntu",
                    "empty_layer": true
                },
                {
                    "created": "2024-08-13T09:27:22.435023547Z",
                    "created_by": "/bin/sh -c #(nop)  LABEL org.opencontainers.image.version=22.04",
                    "empty_layer": true
                },
                {
                    "created": "2024-08-13T09:27:24.259075912Z",
                    "created_by": "/bin/sh -c #(nop) ADD file:2f8a54a5efd080fb81efea702b4e3e07d946eec7563fb2281bd28950c10ec462 in / "
                },
                {
                    "created": "2024-08-13T09:27:24.541222744Z",
                    "created_by": "/bin/sh -c #(nop)  CMD [\"/bin/bash\"]",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:31:19.23391015Z",
                    "created_by": "USER root",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:31:19.23391015Z",
                    "created_by": "ARG GO_VERSION=1.22.6",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:31:19.23391015Z",
                    "created_by": "ARG TARGETARCH=amd64",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:31:19.23391015Z",
                    "created_by": "ARG TARGETVARIANT=",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:31:19.23391015Z",
                    "created_by": "ENV DEBIAN_FRONTEND=noninteractive",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:31:19.23391015Z",
                    "created_by": "ENV EXTERNAL_GRPC_BACKENDS=coqui:/build/backend/python/coqui/run.sh,huggingface-embeddings:/build/backend/python/sentencetransformers/run.sh,transformers:/build/backend/python/transformers/run.sh,sentencetransformers:/build/backend/python/sentencetransformers/run.sh,rerankers:/build/backend/python/rerankers/run.sh,autogptq:/build/backend/python/autogptq/run.sh,bark:/build/backend/python/bark/run.sh,diffusers:/build/backend/python/diffusers/run.sh,exllama:/build/backend/python/exllama/run.sh,openvoice:/build/backend/python/openvoice/run.sh,vall-e-x:/build/backend/python/vall-e-x/run.sh,vllm:/build/backend/python/vllm/run.sh,mamba:/build/backend/python/mamba/run.sh,exllama2:/build/backend/python/exllama2/run.sh,transformers-musicgen:/build/backend/python/transformers-musicgen/run.sh,parler-tts:/build/backend/python/parler-tts/run.sh",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:31:19.23391015Z",
                    "created_by": "RUN |3 GO_VERSION=1.22.6 TARGETARCH=amd64 TARGETVARIANT= /bin/sh -c apt-get update &&     apt-get install -y --no-install-recommends         build-essential         ccache         ca-certificates         cmake         curl         git         unzip upx-ucl &&     apt-get clean &&     rm -rf /var/lib/apt/lists/* # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:31:22.599996663Z",
                    "created_by": "RUN |3 GO_VERSION=1.22.6 TARGETARCH=amd64 TARGETVARIANT= /bin/sh -c curl -L -s https://go.dev/dl/go${GO_VERSION}.linux-${TARGETARCH}.tar.gz | tar -C /usr/local -xz # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:31:22.599996663Z",
                    "created_by": "ENV PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/root/go/bin:/usr/local/go/bin",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:31:32.635244635Z",
                    "created_by": "RUN |3 GO_VERSION=1.22.6 TARGETARCH=amd64 TARGETVARIANT= /bin/sh -c go install google.golang.org/protobuf/cmd/protoc-gen-go@v1.34.2 &&     go install google.golang.org/grpc/cmd/protoc-gen-go-grpc@1958fcbe2ca8bd93af633f11e97d44e567e945af # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:31:32.699568969Z",
                    "created_by": "COPY --chmod=644 custom-ca-certs/* /usr/local/share/ca-certificates/ # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:31:33.101361982Z",
                    "created_by": "RUN |3 GO_VERSION=1.22.6 TARGETARCH=amd64 TARGETVARIANT= /bin/sh -c update-ca-certificates # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:31:33.161856851Z",
                    "created_by": "RUN |3 GO_VERSION=1.22.6 TARGETARCH=amd64 TARGETVARIANT= /bin/sh -c test -n \"$TARGETARCH\"     || (echo 'warn: missing $TARGETARCH, either set this `ARG` manually, or run using `docker buildkit`') # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:31:33.207388064Z",
                    "created_by": "RUN |3 GO_VERSION=1.22.6 TARGETARCH=amd64 TARGETVARIANT= /bin/sh -c echo \"Target Architecture: $TARGETARCH\" # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:31:33.252485641Z",
                    "created_by": "RUN |3 GO_VERSION=1.22.6 TARGETARCH=amd64 TARGETVARIANT= /bin/sh -c echo \"Target Variant: $TARGETVARIANT\" # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:31:33.252485641Z",
                    "created_by": "ENV PATH=/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/root/go/bin:/usr/local/go/bin",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:31:33.252485641Z",
                    "created_by": "ENV PATH=/opt/rocm/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/root/go/bin:/usr/local/go/bin",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:32:25.022254373Z",
                    "created_by": "RUN |3 GO_VERSION=1.22.6 TARGETARCH=amd64 TARGETVARIANT= /bin/sh -c apt-get update &&     apt-get install -y --no-install-recommends         libopenblas-dev         libopencv-dev &&     apt-get clean &&     rm -rf /var/lib/apt/lists/* # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:32:25.87241443Z",
                    "created_by": "RUN |3 GO_VERSION=1.22.6 TARGETARCH=amd64 TARGETVARIANT= /bin/sh -c ln -s /usr/include/opencv4/opencv2 /usr/include/opencv2 # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:32:26.591956694Z",
                    "created_by": "WORKDIR /build"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:32:26.591956694Z",
                    "created_by": "ARG BUILD_TYPE=",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:32:26.591956694Z",
                    "created_by": "ARG CUDA_MAJOR_VERSION=",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:32:26.591956694Z",
                    "created_by": "ARG CUDA_MINOR_VERSION=",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:32:26.591956694Z",
                    "created_by": "ENV BUILD_TYPE=",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:32:27.426934861Z",
                    "created_by": "RUN |6 GO_VERSION=1.22.6 TARGETARCH=amd64 TARGETVARIANT= BUILD_TYPE= CUDA_MAJOR_VERSION= CUDA_MINOR_VERSION= /bin/sh -c <<EOT bash\n    if [ \"${BUILD_TYPE}\" = \"vulkan\" ]; then\n        apt-get update && \\\n        apt-get install -y  --no-install-recommends \\\n            software-properties-common pciutils wget gpg-agent && \\\n        wget -qO - https://packages.lunarg.com/lunarg-signing-key-pub.asc | apt-key add - && \\\n        wget -qO /etc/apt/sources.list.d/lunarg-vulkan-jammy.list https://packages.lunarg.com/vulkan/lunarg-vulkan-jammy.list && \\\n        apt-get update && \\\n        apt-get install -y \\\n            vulkan-sdk && \\\n        apt-get clean && \\\n        rm -rf /var/lib/apt/lists/*\n    fi\nEOT # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:32:28.168475826Z",
                    "created_by": "RUN |6 GO_VERSION=1.22.6 TARGETARCH=amd64 TARGETVARIANT= BUILD_TYPE= CUDA_MAJOR_VERSION= CUDA_MINOR_VERSION= /bin/sh -c <<EOT bash\n    if [ \"${BUILD_TYPE}\" = \"cublas\" ]; then\n        apt-get update && \\\n        apt-get install -y  --no-install-recommends \\\n            software-properties-common pciutils\n        if [ \"amd64\" = \"$TARGETARCH\" ]; then\n            curl -O https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.1-1_all.deb\n        fi\n        if [ \"arm64\" = \"$TARGETARCH\" ]; then\n            curl -O https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/arm64/cuda-keyring_1.1-1_all.deb\n        fi\n        dpkg -i cuda-keyring_1.1-1_all.deb && \\\n        rm -f cuda-keyring_1.1-1_all.deb && \\\n        apt-get update && \\\n        apt-get install -y --no-install-recommends \\\n            cuda-nvcc-${CUDA_MAJOR_VERSION}-${CUDA_MINOR_VERSION} \\\n            libcufft-dev-${CUDA_MAJOR_VERSION}-${CUDA_MINOR_VERSION} \\\n            libcurand-dev-${CUDA_MAJOR_VERSION}-${CUDA_MINOR_VERSION} \\\n            libcublas-dev-${CUDA_MAJOR_VERSION}-${CUDA_MINOR_VERSION} \\\n            libcusparse-dev-${CUDA_MAJOR_VERSION}-${CUDA_MINOR_VERSION} \\\n            libcusolver-dev-${CUDA_MAJOR_VERSION}-${CUDA_MINOR_VERSION} && \\\n        apt-get clean && \\\n        rm -rf /var/lib/apt/lists/*\n    fi\nEOT # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:32:29.09731286Z",
                    "created_by": "RUN |6 GO_VERSION=1.22.6 TARGETARCH=amd64 TARGETVARIANT= BUILD_TYPE= CUDA_MAJOR_VERSION= CUDA_MINOR_VERSION= /bin/sh -c if [ \"${BUILD_TYPE}\" = \"clblas\" ]; then         apt-get update &&         apt-get install -y --no-install-recommends             libclblast-dev &&         apt-get clean &&         rm -rf /var/lib/apt/lists/*     ; fi # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:32:29.958538686Z",
                    "created_by": "RUN |6 GO_VERSION=1.22.6 TARGETARCH=amd64 TARGETVARIANT= BUILD_TYPE= CUDA_MAJOR_VERSION= CUDA_MINOR_VERSION= /bin/sh -c if [ \"${BUILD_TYPE}\" = \"hipblas\" ]; then         apt-get update &&         apt-get install -y --no-install-recommends             hipblas-dev             rocblas-dev &&         apt-get clean &&         rm -rf /var/lib/apt/lists/* &&         ldconfig     ; fi # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:32:29.958538686Z",
                    "created_by": "ARG FFMPEG=true",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:32:29.958538686Z",
                    "created_by": "ARG BUILD_TYPE=",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:32:29.958538686Z",
                    "created_by": "ARG TARGETARCH=amd64",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:32:29.958538686Z",
                    "created_by": "ARG IMAGE_TYPE=core",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:32:29.958538686Z",
                    "created_by": "ARG EXTRA_BACKENDS",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:32:29.958538686Z",
                    "created_by": "ARG MAKEFLAGS=--jobs=4 --output-sync=target",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:32:29.958538686Z",
                    "created_by": "ENV BUILD_TYPE=",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:32:29.958538686Z",
                    "created_by": "ENV REBUILD=false",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:32:29.958538686Z",
                    "created_by": "ENV HEALTHCHECK_ENDPOINT=http://localhost:8080/readyz",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:32:29.958538686Z",
                    "created_by": "ENV MAKEFLAGS=--jobs=4 --output-sync=target",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:32:29.958538686Z",
                    "created_by": "ARG CUDA_MAJOR_VERSION=",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:32:29.958538686Z",
                    "created_by": "ENV NVIDIA_DRIVER_CAPABILITIES=compute,utility",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:32:29.958538686Z",
                    "created_by": "ENV NVIDIA_REQUIRE_CUDA=cuda>=.0",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:32:29.958538686Z",
                    "created_by": "ENV NVIDIA_VISIBLE_DEVICES=all",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:32:41.367006434Z",
                    "created_by": "RUN |13 GO_VERSION=1.22.6 TARGETARCH=amd64 TARGETVARIANT= BUILD_TYPE= CUDA_MAJOR_VERSION= CUDA_MINOR_VERSION= FFMPEG=true BUILD_TYPE= TARGETARCH=amd64 IMAGE_TYPE=core EXTRA_BACKENDS= MAKEFLAGS=--jobs=4 --output-sync=target CUDA_MAJOR_VERSION= /bin/sh -c if [ \"${FFMPEG}\" = \"true\" ]; then         apt-get update &&         apt-get install -y --no-install-recommends             ffmpeg &&         apt-get clean &&         rm -rf /var/lib/apt/lists/*     ; fi # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:32:41.409965583Z",
                    "created_by": "WORKDIR /build"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:32:41.581839237Z",
                    "created_by": "COPY . . # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:47:43.543801521Z",
                    "created_by": "COPY /build/sources ./sources/ # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:47:46.999418197Z",
                    "created_by": "COPY /opt/grpc /usr/local # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:48:16.33820415Z",
                    "created_by": "RUN |13 GO_VERSION=1.22.6 TARGETARCH=amd64 TARGETVARIANT= BUILD_TYPE= CUDA_MAJOR_VERSION= CUDA_MINOR_VERSION= FFMPEG=true BUILD_TYPE= TARGETARCH=amd64 IMAGE_TYPE=core EXTRA_BACKENDS= MAKEFLAGS=--jobs=4 --output-sync=target CUDA_MAJOR_VERSION= /bin/sh -c make prepare-sources # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:48:17.926096859Z",
                    "created_by": "COPY /build/local-ai ./ # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:48:18.075580173Z",
                    "created_by": "COPY /build/sources/go-piper/piper-phonemize/pi/lib/* /usr/lib/ # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:48:18.119787901Z",
                    "created_by": "COPY /build/backend-assets/grpc/stablediffusion ./backend-assets/grpc/stablediffusion # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:48:18.119787901Z",
                    "created_by": "SHELL [/bin/bash -c]",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:48:18.179875481Z",
                    "created_by": "RUN |13 GO_VERSION=1.22.6 TARGETARCH=amd64 TARGETVARIANT= BUILD_TYPE= CUDA_MAJOR_VERSION= CUDA_MINOR_VERSION= FFMPEG=true BUILD_TYPE= TARGETARCH=amd64 IMAGE_TYPE=core EXTRA_BACKENDS= MAKEFLAGS=--jobs=4 --output-sync=target CUDA_MAJOR_VERSION= /bin/bash -c if [[ ( \"${EXTRA_BACKENDS}\" =~ \"coqui\" || -z \"${EXTRA_BACKENDS}\" ) && \"$IMAGE_TYPE\" == \"extras\" ]]; then         make -C backend/python/coqui     ; fi &&     if [[ ( \"${EXTRA_BACKENDS}\" =~ \"parler-tts\" || -z \"${EXTRA_BACKENDS}\" ) && \"$IMAGE_TYPE\" == \"extras\" ]]; then         make -C backend/python/parler-tts     ; fi &&     if [[ ( \"${EXTRA_BACKENDS}\" =~ \"diffusers\" || -z \"${EXTRA_BACKENDS}\" ) && \"$IMAGE_TYPE\" == \"extras\" ]]; then         make -C backend/python/diffusers     ; fi &&     if [[ ( \"${EXTRA_BACKENDS}\" =~ \"transformers-musicgen\" || -z \"${EXTRA_BACKENDS}\" ) && \"$IMAGE_TYPE\" == \"extras\" ]]; then         make -C backend/python/transformers-musicgen     ; fi &&     if [[ ( \"${EXTRA_BACKENDS}\" =~ \"exllama1\" || -z \"${EXTRA_BACKENDS}\" ) && \"$IMAGE_TYPE\" == \"extras\" ]]; then         make -C backend/python/exllama     ; fi # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:48:18.333902098Z",
                    "created_by": "RUN |13 GO_VERSION=1.22.6 TARGETARCH=amd64 TARGETVARIANT= BUILD_TYPE= CUDA_MAJOR_VERSION= CUDA_MINOR_VERSION= FFMPEG=true BUILD_TYPE= TARGETARCH=amd64 IMAGE_TYPE=core EXTRA_BACKENDS= MAKEFLAGS=--jobs=4 --output-sync=target CUDA_MAJOR_VERSION= /bin/bash -c if [[ ( \"${EXTRA_BACKENDS}\" =~ \"vall-e-x\" || -z \"${EXTRA_BACKENDS}\" ) && \"$IMAGE_TYPE\" == \"extras\" ]]; then         make -C backend/python/vall-e-x     ; fi &&     if [[ ( \"${EXTRA_BACKENDS}\" =~ \"openvoice\" || -z \"${EXTRA_BACKENDS}\" ) && \"$IMAGE_TYPE\" == \"extras\" ]]; then         make -C backend/python/openvoice     ; fi &&     if [[ ( \"${EXTRA_BACKENDS}\" =~ \"sentencetransformers\" || -z \"${EXTRA_BACKENDS}\" ) && \"$IMAGE_TYPE\" == \"extras\" ]]; then         make -C backend/python/sentencetransformers     ; fi &&     if [[ ( \"${EXTRA_BACKENDS}\" =~ \"exllama2\" || -z \"${EXTRA_BACKENDS}\" ) && \"$IMAGE_TYPE\" == \"extras\" ]]; then         make -C backend/python/exllama2     ; fi &&     if [[ ( \"${EXTRA_BACKENDS}\" =~ \"transformers\" || -z \"${EXTRA_BACKENDS}\" ) && \"$IMAGE_TYPE\" == \"extras\" ]]; then         make -C backend/python/transformers     ; fi # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:48:18.402329687Z",
                    "created_by": "RUN |13 GO_VERSION=1.22.6 TARGETARCH=amd64 TARGETVARIANT= BUILD_TYPE= CUDA_MAJOR_VERSION= CUDA_MINOR_VERSION= FFMPEG=true BUILD_TYPE= TARGETARCH=amd64 IMAGE_TYPE=core EXTRA_BACKENDS= MAKEFLAGS=--jobs=4 --output-sync=target CUDA_MAJOR_VERSION= /bin/bash -c if [[ ( \"${EXTRA_BACKENDS}\" =~ \"vllm\" || -z \"${EXTRA_BACKENDS}\" ) && \"$IMAGE_TYPE\" == \"extras\" ]]; then         make -C backend/python/vllm     ; fi &&     if [[ ( \"${EXTRA_BACKENDS}\" =~ \"autogptq\" || -z \"${EXTRA_BACKENDS}\" ) && \"$IMAGE_TYPE\" == \"extras\" ]]; then         make -C backend/python/autogptq     ; fi &&     if [[ ( \"${EXTRA_BACKENDS}\" =~ \"bark\" || -z \"${EXTRA_BACKENDS}\" ) && \"$IMAGE_TYPE\" == \"extras\" ]]; then         make -C backend/python/bark     ; fi &&     if [[ ( \"${EXTRA_BACKENDS}\" =~ \"rerankers\" || -z \"${EXTRA_BACKENDS}\" ) && \"$IMAGE_TYPE\" == \"extras\" ]]; then         make -C backend/python/rerankers     ; fi &&     if [[ ( \"${EXTRA_BACKENDS}\" =~ \"mamba\" || -z \"${EXTRA_BACKENDS}\" ) && \"$IMAGE_TYPE\" == \"extras\" ]]; then         make -C backend/python/mamba     ; fi # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:48:18.474708463Z",
                    "created_by": "RUN |13 GO_VERSION=1.22.6 TARGETARCH=amd64 TARGETVARIANT= BUILD_TYPE= CUDA_MAJOR_VERSION= CUDA_MINOR_VERSION= FFMPEG=true BUILD_TYPE= TARGETARCH=amd64 IMAGE_TYPE=core EXTRA_BACKENDS= MAKEFLAGS=--jobs=4 --output-sync=target CUDA_MAJOR_VERSION= /bin/bash -c mkdir -p /build/models # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:48:18.474708463Z",
                    "created_by": "HEALTHCHECK &{[\"CMD-SHELL\" \"curl -f ${HEALTHCHECK_ENDPOINT} || exit 1\"] \"1m0s\" \"10m0s\" \"0s\" \"0s\" '\\n'}",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:48:18.474708463Z",
                    "created_by": "VOLUME [/build/models]",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:48:18.474708463Z",
                    "created_by": "EXPOSE map[8080/tcp:{}]",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T08:48:18.474708463Z",
                    "created_by": "ENTRYPOINT [\"/build/entrypoint.sh\"]",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T10:57:42.731885245Z",
                    "created_by": "RUN /bin/bash -c apt-get update && apt-get install -y pciutils && apt-get clean # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T10:57:42.822902737Z",
                    "created_by": "COPY aio/ /aio # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-23T10:57:42.822902737Z",
                    "created_by": "ENTRYPOINT [\"/aio/entrypoint.sh\"]",
                    "empty_layer": true
                }
            ],
            "creation_time": "2024-09-10 04:29:12.890000+00:00",
            "description": "[author]: <> (Ettore Di Giacinto)\n[subTitle]: <> (LocalAI is the free, Open Source OpenAI alternative)\n[shortDescription]: <> (The free, Open Source alternative to OpenAI, Claude and others. Self-hosted and local-first. Drop-in replacement for OpenAI, running on consumer-grade hardware. No GPU required. Runs gguf, transformers, diffusers and many more models architectures. Features: Generate Text, Audio, Video, Images, Voice Cloning, Distributed inference)\n\n\n<h1 align=\"center\">\n  <br>\n  <img height=\"300\" src=\"https://github.com/go-skynet/LocalAI/assets/2420543/0966aa2a-166e-4f99-a3e5-6c915fc997dd\"> <br>\n    LocalAI\n<br>\n</h1>\n\n<p align=\"center\">\n<a href=\"https://github.com/go-skynet/LocalAI/fork\" target=\"blank\">\n<img src=\"https://img.shields.io/github/forks/go-skynet/LocalAI?style=for-the-badge\" alt=\"LocalAI forks\"/>\n</a>\n<a href=\"https://github.com/go-skynet/LocalAI/stargazers\" target=\"blank\">\n<img src=\"https://img.shields.io/github/stars/go-skynet/LocalAI?style=for-the-badge\" alt=\"LocalAI stars\"/>\n</a>\n<a href=\"https://github.com/go-skynet/LocalAI/pulls\" target=\"blank\">\n<img src=\"https://img.shields.io/github/issues-pr/go-skynet/LocalAI?style=for-the-badge\" alt=\"LocalAI pull-requests\"/>\n</a>\n<a href='https://github.com/go-skynet/LocalAI/releases'>\n<img src='https://img.shields.io/github/release/go-skynet/LocalAI?&label=Latest&style=for-the-badge'>\n</a>\n</p>\n\n<p align=\"center\">\n<a href=\"https://hub.docker.com/r/localai/localai\" target=\"blank\">\n<img src=\"https://img.shields.io/badge/dockerhub-images-important.svg?logo=Docker\" alt=\"LocalAI Docker hub\"/>\n</a>\n<a href=\"https://quay.io/repository/go-skynet/local-ai?tab=tags&tag=latest\" target=\"blank\">\n<img src=\"https://img.shields.io/badge/quay.io-images-important.svg?\" alt=\"LocalAI Quay.io\"/>\n</a>\n</p>\n\n<p align=\"center\">\n<a href=\"https://twitter.com/LocalAI_API\" target=\"blank\">\n<img src=\"https://img.shields.io/twitter/follow/LocalAI_API?label=Follow: LocalAI_API&style=social\" alt=\"Follow LocalAI_API\"/>\n</a>\n<a href=\"https://discord.gg/uJAeKSAGDy\" target=\"blank\">\n<img src=\"https://dcbadge.vercel.app/api/server/uJAeKSAGDy?style=flat-square&theme=default-inverted\" alt=\"Join LocalAI Discord Community\"/>\n</a>\n</p>\n\n> :bulb: Get help - [\u2753FAQ](https://localai.io/faq/) [\ud83d\udcadDiscussions](https://github.com/go-skynet/LocalAI/discussions) [:speech_balloon: Discord](https://discord.gg/uJAeKSAGDy) [:book: Documentation website](https://localai.io/)\n>\n> [\ud83d\udcbb Quickstart](https://localai.io/basics/getting_started/) [\ud83d\uddbc\ufe0f Models](https://models.localai.io/) [\ud83d\ude80 Roadmap](https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap) [\ud83e\udd7d Demo](https://demo.localai.io) [\ud83c\udf0d Explorer](https://explorer.localai.io) [\ud83d\udeeb Examples](https://github.com/go-skynet/LocalAI/tree/master/examples/) \n\n[![tests](https://github.com/go-skynet/LocalAI/actions/workflows/test.yml/badge.svg)](https://github.com/go-skynet/LocalAI/actions/workflows/test.yml)[![Build and Release](https://github.com/go-skynet/LocalAI/actions/workflows/release.yaml/badge.svg)](https://github.com/go-skynet/LocalAI/actions/workflows/release.yaml)[![build container images](https://github.com/go-skynet/LocalAI/actions/workflows/image.yml/badge.svg)](https://github.com/go-skynet/LocalAI/actions/workflows/image.yml)[![Bump dependencies](https://github.com/go-skynet/LocalAI/actions/workflows/bump_deps.yaml/badge.svg)](https://github.com/go-skynet/LocalAI/actions/workflows/bump_deps.yaml)[![Artifact Hub](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/localai)](https://artifacthub.io/packages/search?repo=localai)\n\n**LocalAI** is the free, Open Source OpenAI alternative. LocalAI act as a drop-in replacement REST API that\u2019s compatible with OpenAI (Elevenlabs, Anthropic... ) API specifications for local AI inferencing. It allows you to run LLMs, generate images, audio (and not only) locally or on-prem with consumer grade hardware, supporting multiple model families. Does not require GPU. It is created and maintained by [Ettore Di Giacinto](https://github.com/mudler).\n\n![screen](https://github.com/mudler/LocalAI/assets/2420543/20b5ccd2-8393-44f0-aaf6-87a23806381e)\n\nRun the installer script:\n\n```bash\ncurl https://localai.io/install.sh | sh\n```\n\nOr run with docker:\n```bash\ndocker run -ti --name local-ai -p 8080:8080 localai/localai:latest-aio-cpu\n# Alternative images:\n# - if you have an Nvidia GPU:\n# docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-aio-gpu-nvidia-cuda-12\n# - without preconfigured models\n# docker run -ti --name local-ai -p 8080:8080 localai/localai:latest\n# - without preconfigured models for Nvidia GPUs\n# docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-gpu-nvidia-cuda-12 \n```\n\n[\ud83d\udcbb Getting started](https://localai.io/basics/getting_started/index.html)\n\n## \ud83d\udd25\ud83d\udd25 Hot topics / Roadmap\n\n[Roadmap](https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap)\n\n- Aug 2024:  \ud83c\udd95 FLUX-1, [P2P Explorer](https://explorer.localai.io)\n- July 2024: \ud83d\udd25\ud83d\udd25 \ud83c\udd95 P2P Dashboard, LocalAI Federated mode and AI Swarms: https://github.com/mudler/LocalAI/pull/2723\n- June 2024: \ud83c\udd95 You can browse now the model gallery without LocalAI! Check out https://models.localai.io\n- June 2024: Support for models from OCI registries: https://github.com/mudler/LocalAI/pull/2628\n- May 2024: \ud83d\udd25\ud83d\udd25 Decentralized P2P llama.cpp:  https://github.com/mudler/LocalAI/pull/2343 (peer2peer llama.cpp!) \ud83d\udc49 Docs  https://localai.io/features/distribute/\n- May 2024: \ud83d\udd25\ud83d\udd25 Openvoice: https://github.com/mudler/LocalAI/pull/2334\n- May 2024: \ud83c\udd95 Function calls without grammars and mixed mode: https://github.com/mudler/LocalAI/pull/2328\n- May 2024: \ud83d\udd25\ud83d\udd25 Distributed inferencing: https://github.com/mudler/LocalAI/pull/2324\n- May 2024: Chat, TTS, and Image generation in the WebUI: https://github.com/mudler/LocalAI/pull/2222\n- April 2024: Reranker API: https://github.com/mudler/LocalAI/pull/2121\n\nHot topics (looking for contributors):\n\n- \ud83d\udd25\ud83d\udd25 Distributed, P2P Global community pools: https://github.com/mudler/LocalAI/issues/3113\n- WebUI improvements: https://github.com/mudler/LocalAI/issues/2156\n- Backends v2: https://github.com/mudler/LocalAI/issues/1126\n- Improving UX v2: https://github.com/mudler/LocalAI/issues/1373\n- Assistant API: https://github.com/mudler/LocalAI/issues/1273\n- Moderation endpoint: https://github.com/mudler/LocalAI/issues/999\n- Vulkan: https://github.com/mudler/LocalAI/issues/1647\n- Anthropic API: https://github.com/mudler/LocalAI/issues/1808\n\nIf you want to help and contribute, issues up for grabs: https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3A%22up+for+grabs%22\n\n## \ud83d\ude80 [Features](https://localai.io/features/)\n\n- \ud83d\udcd6 [Text generation with GPTs](https://localai.io/features/text-generation/) (`llama.cpp`, `gpt4all.cpp`, ... [:book: and more](https://localai.io/model-compatibility/index.html#model-compatibility-table))\n- \ud83d\udde3 [Text to Audio](https://localai.io/features/text-to-audio/)\n- \ud83d\udd08 [Audio to Text](https://localai.io/features/audio-to-text/) (Audio transcription with `whisper.cpp`)\n- \ud83c\udfa8 [Image generation with stable diffusion](https://localai.io/features/image-generation)\n- \ud83d\udd25 [OpenAI-alike tools API](https://localai.io/features/openai-functions/) \n- \ud83e\udde0 [Embeddings generation for vector databases](https://localai.io/features/embeddings/)\n- \u270d\ufe0f [Constrained grammars](https://localai.io/features/constrained_grammars/)\n- \ud83d\uddbc\ufe0f [Download Models directly from Huggingface ](https://localai.io/models/)\n- \ud83e\udd7d [Vision API](https://localai.io/features/gpt-vision/)\n- \ud83d\udcc8 [Reranker API](https://localai.io/features/reranker/)\n- \ud83c\udd95\ud83d\udda7 [P2P Inferencing](https://localai.io/features/distribute/)\n- \ud83c\udf0d Integrated WebUI!\n\n## \ud83d\udcbb Usage\n\nCheck out the [Getting started](https://localai.io/basics/getting_started/index.html) section in our documentation.\n\n### \ud83d\udd17 Community and integrations\n\nBuild and deploy custom containers:\n- https://github.com/sozercan/aikit\n\nWebUIs:\n- https://github.com/Jirubizu/localai-admin\n- https://github.com/go-skynet/LocalAI-frontend\n- QA-Pilot(An interactive chat project that leverages LocalAI LLMs for rapid understanding and navigation of GitHub code repository) https://github.com/reid41/QA-Pilot\n\nModel galleries\n- https://github.com/go-skynet/model-gallery\n\nOther:\n- Helm chart https://github.com/go-skynet/helm-charts\n- VSCode extension https://github.com/badgooooor/localai-vscode-plugin\n- Terminal utility https://github.com/djcopley/ShellOracle\n- Local Smart assistant https://github.com/mudler/LocalAGI\n- Home Assistant https://github.com/sammcj/homeassistant-localai / https://github.com/drndos/hass-openai-custom-conversation / https://github.com/valentinfrlch/ha-gpt4vision\n- Discord bot https://github.com/mudler/LocalAGI/tree/main/examples/discord\n- Slack bot https://github.com/mudler/LocalAGI/tree/main/examples/slack\n- Shell-Pilot(Interact with LLM using LocalAI models via pure shell scripts on your Linux or MacOS system) https://github.com/reid41/shell-pilot\n- Telegram bot https://github.com/mudler/LocalAI/tree/master/examples/telegram-bot\n- Github Actions: https://github.com/marketplace/actions/start-localai\n- Examples: https://github.com/mudler/LocalAI/tree/master/examples/\n  \n\n### \ud83d\udd17 Resources\n\n- [LLM finetuning guide](https://localai.io/docs/advanced/fine-tuning/)\n- [How to build locally](https://localai.io/basics/build/index.html)\n- [How to install in Kubernetes](https://localai.io/basics/getting_started/index.html#run-localai-in-kubernetes)\n- [Projects integrating LocalAI](https://localai.io/docs/integrations/)\n- [How tos section](https://io.midori-ai.xyz/howtos/) (curated by our community)\n\n## :book: \ud83c\udfa5 [Media, Blogs, Social](https://localai.io/basics/news/#media-blogs-social)\n\n- [Run Visual studio code with LocalAI (SUSE)](https://www.suse.com/c/running-ai-locally/)\n- \ud83c\udd95 [Run LocalAI on Jetson Nano Devkit](https://mudler.pm/posts/local-ai-jetson-nano-devkit/)\n- [Run LocalAI on AWS EKS with Pulumi](https://www.pulumi.com/blog/low-code-llm-apps-with-local-ai-flowise-and-pulumi/)\n- [Run LocalAI on AWS](https://staleks.hashnode.dev/installing-localai-on-aws-ec2-instance)\n- [Create a slackbot for teams and OSS projects that answer to documentation](https://mudler.pm/posts/smart-slackbot-for-teams/)\n- [LocalAI meets k8sgpt](https://www.youtube.com/watch?v=PKrDNuJ_dfE)\n- [Question Answering on Documents locally with LangChain, LocalAI, Chroma, and GPT4All](https://mudler.pm/posts/localai-question-answering/)\n- [Tutorial to use k8sgpt with LocalAI](https://medium.com/@tyler_97636/k8sgpt-localai-unlock-kubernetes-superpowers-for-free-584790de9b65)\n\n## Citation\n\nIf you utilize this repository, data in a downstream project, please consider citing it with:\n\n```\n@misc{localai,\n  author = {Ettore Di Giacinto},\n  title = {LocalAI: The free, Open source OpenAI alternative},\n  year = {2023},\n  publisher = {GitHub},\n  journal = {GitHub repository},\n  howpublished = {\\url{https://github.com/go-skynet/LocalAI}},\n```\n\n## \u2764\ufe0f Sponsors\n\n> Do you find LocalAI useful?\n\nSupport the project by becoming [a backer or sponsor](https://github.com/sponsors/mudler). Your logo will show up here with a link to your website.\n\nA huge thank you to our generous sponsors who support this project covering CI expenses, and our [Sponsor list](https://github.com/sponsors/mudler):\n\n<p align=\"center\">\n  <a href=\"https://www.spectrocloud.com/\" target=\"blank\">\n    <img height=\"200\" src=\"https://github.com/go-skynet/LocalAI/assets/2420543/68a6f3cb-8a65-4a4d-99b5-6417a8905512\">\n  </a>\n  <a href=\"https://www.premai.io/\" target=\"blank\">\n    <img height=\"200\" src=\"https://github.com/mudler/LocalAI/assets/2420543/42e4ca83-661e-4f79-8e46-ae43689683d6\"> <br>\n  </a>\n</p>\n\n## \ud83c\udf1f Star history\n\n[![LocalAI Star history Chart](https://api.star-history.com/svg?repos=go-skynet/LocalAI&type=Date)](https://star-history.com/#go-skynet/LocalAI&Date)\n\n## \ud83d\udcd6 License\n\nLocalAI is a community-driven project created by [Ettore Di Giacinto](https://github.com/mudler/).\n\nMIT - Author Ettore Di Giacinto <mudler@localai.io>\n\n## \ud83d\ude47 Acknowledgements\n\nLocalAI couldn't have been built without the help of great software already available from the community. Thank you!\n\n- [llama.cpp](https://github.com/ggerganov/llama.cpp)\n- https://github.com/tatsu-lab/stanford_alpaca\n- https://github.com/cornelk/llama-go for the initial ideas\n- https://github.com/antimatter15/alpaca.cpp\n- https://github.com/EdVince/Stable-Diffusion-NCNN\n- https://github.com/ggerganov/whisper.cpp\n- https://github.com/saharNooby/rwkv.cpp\n- https://github.com/rhasspy/piper\n\n## \ud83e\udd17 Contributors\n\nThis is a community project, a special thanks to our contributors! \ud83e\udd17\n<a href=\"https://github.com/go-skynet/LocalAI/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=go-skynet/LocalAI\" />\n</a>\n",
            "id": 41,
            "metadata": {
                "author": "Ettore Di Giacinto",
                "shortDescription": "The free, Open Source alternative to OpenAI, Claude and others. Self-hosted and local-first. Drop-in replacement for OpenAI, running on consumer-grade hardware. No GPU required. Runs gguf, transformers, diffusers and many more models architectures. Features: Generate Text, Audio, Video, Images, Voice Cloning, Distributed inference",
                "subTitle": "LocalAI is the free, Open Source OpenAI alternative"
            },
            "name": "ai/localai",
            "project_id": 34,
            "pull_count": 2,
            "update_time": "2024-09-13 03:34:40.887000+00:00"
        },
        {
            "artifact_count": 1,
            "artifacts": [
                {
                    "accessories": null,
                    "addition_links": {
                        "build_history": {
                            "absolute": false,
                            "href": "/api/v2.0/projects/ai/repositories/ollama/artifacts/sha256:01410d682d1394839a0e4c0a983ef7036984ff6da815285336aaeecafe963abe/additions/build_history"
                        },
                        "vulnerabilities": {
                            "absolute": false,
                            "href": "/api/v2.0/projects/ai/repositories/ollama/artifacts/sha256:01410d682d1394839a0e4c0a983ef7036984ff6da815285336aaeecafe963abe/additions/vulnerabilities"
                        }
                    },
                    "annotations": null,
                    "digest": "sha256:01410d682d1394839a0e4c0a983ef7036984ff6da815285336aaeecafe963abe",
                    "extra_attrs": {
                        "architecture": "amd64",
                        "author": "",
                        "config": {
                            "ArgsEscaped": true,
                            "Cmd": [
                                "serve"
                            ],
                            "Entrypoint": [
                                "/bin/ollama"
                            ],
                            "Env": [
                                "PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
                                "OLLAMA_HOST=0.0.0.0",
                                "LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64",
                                "NVIDIA_DRIVER_CAPABILITIES=compute,utility",
                                "NVIDIA_VISIBLE_DEVICES=all"
                            ],
                            "ExposedPorts": {
                                "11434/tcp": {}
                            },
                            "Labels": {
                                "org.opencontainers.image.ref.name": "ubuntu",
                                "org.opencontainers.image.version": "22.04"
                            }
                        },
                        "created": "2024-08-31T18:50:19.602958497Z",
                        "os": "linux"
                    },
                    "icon": "sha256:0048162a053eef4d4ce3fe7518615bef084403614f8bca43b40ae2e762e11e06",
                    "id": 40,
                    "labels": null,
                    "manifest_media_type": "application/vnd.docker.distribution.manifest.v2+json",
                    "media_type": "application/vnd.docker.container.image.v1+json",
                    "project_id": 34,
                    "pull_time": "2024-09-10 08:04:32.078000+00:00",
                    "push_time": "2024-09-10 04:00:36.541000+00:00",
                    "references": null,
                    "repository_id": 40,
                    "scan_overview": null,
                    "size": 1633269694,
                    "tags": [
                        {
                            "artifact_id": 40,
                            "id": 40,
                            "immutable": false,
                            "name": "latest",
                            "pull_time": "2024-09-10 08:04:32.078000+00:00",
                            "push_time": "2024-09-10 04:00:36.945000+00:00",
                            "repository_id": 40,
                            "signed": false
                        }
                    ],
                    "type": "IMAGE"
                }
            ],
            "build_history": [
                {
                    "created": "2024-08-13T09:27:22.357288914Z",
                    "created_by": "/bin/sh -c #(nop)  ARG RELEASE",
                    "empty_layer": true
                },
                {
                    "created": "2024-08-13T09:27:22.382523486Z",
                    "created_by": "/bin/sh -c #(nop)  ARG LAUNCHPAD_BUILD_ARCH",
                    "empty_layer": true
                },
                {
                    "created": "2024-08-13T09:27:22.406703187Z",
                    "created_by": "/bin/sh -c #(nop)  LABEL org.opencontainers.image.ref.name=ubuntu",
                    "empty_layer": true
                },
                {
                    "created": "2024-08-13T09:27:22.435023547Z",
                    "created_by": "/bin/sh -c #(nop)  LABEL org.opencontainers.image.version=22.04",
                    "empty_layer": true
                },
                {
                    "created": "2024-08-13T09:27:24.259075912Z",
                    "created_by": "/bin/sh -c #(nop) ADD file:2f8a54a5efd080fb81efea702b4e3e07d946eec7563fb2281bd28950c10ec462 in / "
                },
                {
                    "created": "2024-08-13T09:27:24.541222744Z",
                    "created_by": "/bin/sh -c #(nop)  CMD [\"/bin/bash\"]",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-31T18:50:08.187209116Z",
                    "created_by": "COPY /scratch/ /lib/ # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-31T18:50:18.304119254Z",
                    "created_by": "RUN /bin/sh -c apt-get update && apt-get install -y ca-certificates # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-31T18:50:19.602958497Z",
                    "created_by": "COPY /go/src/github.com/ollama/ollama/dist/linux-amd64/bin/ /bin/ # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-31T18:50:19.602958497Z",
                    "created_by": "EXPOSE map[11434/tcp:{}]",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-31T18:50:19.602958497Z",
                    "created_by": "ENV OLLAMA_HOST=0.0.0.0",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-31T18:50:19.602958497Z",
                    "created_by": "ENV PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-31T18:50:19.602958497Z",
                    "created_by": "ENV LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-31T18:50:19.602958497Z",
                    "created_by": "ENV NVIDIA_DRIVER_CAPABILITIES=compute,utility",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-31T18:50:19.602958497Z",
                    "created_by": "ENV NVIDIA_VISIBLE_DEVICES=all",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-31T18:50:19.602958497Z",
                    "created_by": "ENTRYPOINT [\"/bin/ollama\"]",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-08-31T18:50:19.602958497Z",
                    "created_by": "CMD [\"serve\"]",
                    "empty_layer": true
                }
            ],
            "creation_time": "2024-09-10 04:00:36.317000+00:00",
            "description": "[author]: <> (Ollama)\n[subTitle]: <> (Get up and running with large language models)\n[shortDescription]: <> (Get up and running with Llama 3.1, Mistral, Gemma 2, and other large language models.)\n\n<div align=\"center\">\n <img alt=\"ollama\" height=\"200px\" src=\"https://github.com/ollama/ollama/assets/3325447/0d0b44e2-8f4a-4e99-9b52-a5c1c741c8f7\">\n</div>\n\n# Ollama\n\n[![Discord](https://dcbadge.vercel.app/api/server/ollama?style=flat&compact=true)](https://discord.gg/ollama)\n\nGet up and running with large language models.\n\n### macOS\n\n[Download](https://ollama.com/download/Ollama-darwin.zip)\n\n### Windows preview\n\n[Download](https://ollama.com/download/OllamaSetup.exe)\n\n### Linux\n\n```\ncurl -fsSL https://ollama.com/install.sh | sh\n```\n\n[Manual install instructions](https://github.com/ollama/ollama/blob/main/docs/linux.md)\n\n### Docker\n\nThe official [Ollama Docker image](https://hub.docker.com/r/ollama/ollama) `ollama/ollama` is available on Docker Hub.\n\n### Libraries\n\n- [ollama-python](https://github.com/ollama/ollama-python)\n- [ollama-js](https://github.com/ollama/ollama-js)\n\n## Quickstart\n\nTo run and chat with [Llama 3.1](https://ollama.com/library/llama3.1):\n\n```\nollama run llama3.1\n```\n\n## Model library\n\nOllama supports a list of models available on [ollama.com/library](https://ollama.com/library 'ollama model library')\n\nHere are some example models that can be downloaded:\n\n| Model              | Parameters | Size  | Download                       |\n| ------------------ | ---------- | ----- | ------------------------------ |\n| Llama 3.1          | 8B         | 4.7GB | `ollama run llama3.1`          |\n| Llama 3.1          | 70B        | 40GB  | `ollama run llama3.1:70b`      |\n| Llama 3.1          | 405B       | 231GB | `ollama run llama3.1:405b`     |\n| Phi 3 Mini         | 3.8B       | 2.3GB | `ollama run phi3`              |\n| Phi 3 Medium       | 14B        | 7.9GB | `ollama run phi3:medium`       |\n| Gemma 2            | 2B         | 1.6GB | `ollama run gemma2:2b`         |\n| Gemma 2            | 9B         | 5.5GB | `ollama run gemma2`            |\n| Gemma 2            | 27B        | 16GB  | `ollama run gemma2:27b`        |\n| Mistral            | 7B         | 4.1GB | `ollama run mistral`           |\n| Moondream 2        | 1.4B       | 829MB | `ollama run moondream`         |\n| Neural Chat        | 7B         | 4.1GB | `ollama run neural-chat`       |\n| Starling           | 7B         | 4.1GB | `ollama run starling-lm`       |\n| Code Llama         | 7B         | 3.8GB | `ollama run codellama`         |\n| Llama 2 Uncensored | 7B         | 3.8GB | `ollama run llama2-uncensored` |\n| LLaVA              | 7B         | 4.5GB | `ollama run llava`             |\n| Solar              | 10.7B      | 6.1GB | `ollama run solar`             |\n\n> [!NOTE]\n> You should have at least 8 GB of RAM available to run the 7B models, 16 GB to run the 13B models, and 32 GB to run the 33B models.\n\n## Customize a model\n\n### Import from GGUF\n\nOllama supports importing GGUF models in the Modelfile:\n\n1. Create a file named `Modelfile`, with a `FROM` instruction with the local filepath to the model you want to import.\n\n   ```\n   FROM ./vicuna-33b.Q4_0.gguf\n   ```\n\n2. Create the model in Ollama\n\n   ```\n   ollama create example -f Modelfile\n   ```\n\n3. Run the model\n\n   ```\n   ollama run example\n   ```\n\n### Import from PyTorch or Safetensors\n\nSee the [guide](docs/import.md) on importing models for more information.\n\n### Customize a prompt\n\nModels from the Ollama library can be customized with a prompt. For example, to customize the `llama3.1` model:\n\n```\nollama pull llama3.1\n```\n\nCreate a `Modelfile`:\n\n```\nFROM llama3.1\n\n# set the temperature to 1 [higher is more creative, lower is more coherent]\nPARAMETER temperature 1\n\n# set the system message\nSYSTEM \"\"\"\nYou are Mario from Super Mario Bros. Answer as Mario, the assistant, only.\n\"\"\"\n```\n\nNext, create and run the model:\n\n```\nollama create mario -f ./Modelfile\nollama run mario\n>>> hi\nHello! It's your friend Mario.\n```\n\nFor more examples, see the [examples](examples) directory. For more information on working with a Modelfile, see the [Modelfile](docs/modelfile.md) documentation.\n\n## CLI Reference\n\n### Create a model\n\n`ollama create` is used to create a model from a Modelfile.\n\n```\nollama create mymodel -f ./Modelfile\n```\n\n### Pull a model\n\n```\nollama pull llama3.1\n```\n\n> This command can also be used to update a local model. Only the diff will be pulled.\n\n### Remove a model\n\n```\nollama rm llama3.1\n```\n\n### Copy a model\n\n```\nollama cp llama3.1 my-model\n```\n\n### Multiline input\n\nFor multiline input, you can wrap text with `\"\"\"`:\n\n```\n>>> \"\"\"Hello,\n... world!\n... \"\"\"\nI'm a basic program that prints the famous \"Hello, world!\" message to the console.\n```\n\n### Multimodal models\n\n```\nollama run llava \"What's in this image? /Users/jmorgan/Desktop/smile.png\"\nThe image features a yellow smiley face, which is likely the central focus of the picture.\n```\n\n### Pass the prompt as an argument\n\n```\n$ ollama run llama3.1 \"Summarize this file: $(cat README.md)\"\n Ollama is a lightweight, extensible framework for building and running language models on the local machine. It provides a simple API for creating, running, and managing models, as well as a library of pre-built models that can be easily used in a variety of applications.\n```\n\n### Show model information\n\n```\nollama show llama3.1\n```\n\n### List models on your computer\n\n```\nollama list\n```\n\n### Start Ollama\n\n`ollama serve` is used when you want to start ollama without running the desktop application.\n\n## Building\n\nSee the [developer guide](https://github.com/ollama/ollama/blob/main/docs/development.md)\n\n### Running local builds\n\nNext, start the server:\n\n```\n./ollama serve\n```\n\nFinally, in a separate shell, run a model:\n\n```\n./ollama run llama3.1\n```\n\n## REST API\n\nOllama has a REST API for running and managing models.\n\n### Generate a response\n\n```\ncurl http://localhost:11434/api/generate -d '{\n  \"model\": \"llama3.1\",\n  \"prompt\":\"Why is the sky blue?\"\n}'\n```\n\n### Chat with a model\n\n```\ncurl http://localhost:11434/api/chat -d '{\n  \"model\": \"llama3.1\",\n  \"messages\": [\n    { \"role\": \"user\", \"content\": \"why is the sky blue?\" }\n  ]\n}'\n```\n\nSee the [API documentation](./docs/api.md) for all endpoints.\n\n## Community Integrations\n\n### Web & Desktop\n\n- [Open WebUI](https://github.com/open-webui/open-webui)\n- [Enchanted (macOS native)](https://github.com/AugustDev/enchanted)\n- [Hollama](https://github.com/fmaclen/hollama)\n- [Lollms-Webui](https://github.com/ParisNeo/lollms-webui)\n- [LibreChat](https://github.com/danny-avila/LibreChat)\n- [Bionic GPT](https://github.com/bionic-gpt/bionic-gpt)\n- [HTML UI](https://github.com/rtcfirefly/ollama-ui)\n- [Saddle](https://github.com/jikkuatwork/saddle)\n- [Chatbot UI](https://github.com/ivanfioravanti/chatbot-ollama)\n- [Chatbot UI v2](https://github.com/mckaywrigley/chatbot-ui)\n- [Typescript UI](https://github.com/ollama-interface/Ollama-Gui?tab=readme-ov-file)\n- [Minimalistic React UI for Ollama Models](https://github.com/richawo/minimal-llm-ui)\n- [Ollamac](https://github.com/kevinhermawan/Ollamac)\n- [big-AGI](https://github.com/enricoros/big-AGI/blob/main/docs/config-local-ollama.md)\n- [Cheshire Cat assistant framework](https://github.com/cheshire-cat-ai/core)\n- [Amica](https://github.com/semperai/amica)\n- [chatd](https://github.com/BruceMacD/chatd)\n- [Ollama-SwiftUI](https://github.com/kghandour/Ollama-SwiftUI)\n- [Dify.AI](https://github.com/langgenius/dify)\n- [MindMac](https://mindmac.app)\n- [NextJS Web Interface for Ollama](https://github.com/jakobhoeg/nextjs-ollama-llm-ui)\n- [Msty](https://msty.app)\n- [Chatbox](https://github.com/Bin-Huang/Chatbox)\n- [WinForm Ollama Copilot](https://github.com/tgraupmann/WinForm_Ollama_Copilot)\n- [NextChat](https://github.com/ChatGPTNextWeb/ChatGPT-Next-Web) with [Get Started Doc](https://docs.nextchat.dev/models/ollama)\n- [Alpaca WebUI](https://github.com/mmo80/alpaca-webui)\n- [OllamaGUI](https://github.com/enoch1118/ollamaGUI)\n- [OpenAOE](https://github.com/InternLM/OpenAOE)\n- [Odin Runes](https://github.com/leonid20000/OdinRunes)\n- [LLM-X](https://github.com/mrdjohnson/llm-x) (Progressive Web App)\n- [AnythingLLM (Docker + MacOs/Windows/Linux native app)](https://github.com/Mintplex-Labs/anything-llm)\n- [Ollama Basic Chat: Uses HyperDiv Reactive UI](https://github.com/rapidarchitect/ollama_basic_chat)\n- [Ollama-chats RPG](https://github.com/drazdra/ollama-chats)\n- [QA-Pilot](https://github.com/reid41/QA-Pilot) (Chat with Code Repository)\n- [ChatOllama](https://github.com/sugarforever/chat-ollama) (Open Source Chatbot based on Ollama with Knowledge Bases)\n- [CRAG Ollama Chat](https://github.com/Nagi-ovo/CRAG-Ollama-Chat) (Simple Web Search with Corrective RAG)\n- [RAGFlow](https://github.com/infiniflow/ragflow) (Open-source Retrieval-Augmented Generation engine based on deep document understanding)\n- [StreamDeploy](https://github.com/StreamDeploy-DevRel/streamdeploy-llm-app-scaffold) (LLM Application Scaffold)\n- [chat](https://github.com/swuecho/chat) (chat web app for teams)\n- [Lobe Chat](https://github.com/lobehub/lobe-chat) with [Integrating Doc](https://lobehub.com/docs/self-hosting/examples/ollama)\n- [Ollama RAG Chatbot](https://github.com/datvodinh/rag-chatbot.git) (Local Chat with multiple PDFs using Ollama and RAG)\n- [BrainSoup](https://www.nurgo-software.com/products/brainsoup) (Flexible native client with RAG & multi-agent automation)\n- [macai](https://github.com/Renset/macai) (macOS client for Ollama, ChatGPT, and other compatible API back-ends)\n- [Olpaka](https://github.com/Otacon/olpaka) (User-friendly Flutter Web App for Ollama)\n- [OllamaSpring](https://github.com/CrazyNeil/OllamaSpring) (Ollama Client for macOS)\n- [LLocal.in](https://github.com/kartikm7/llocal) (Easy to use Electron Desktop Client for Ollama)\n- [AiLama](https://github.com/zeyoyt/ailama) (A Discord User App that allows you to interact with Ollama anywhere in discord )\n- [Ollama with Google Mesop](https://github.com/rapidarchitect/ollama_mesop/) (Mesop Chat Client implementation with Ollama)\n- [Painting Droid](https://github.com/mateuszmigas/painting-droid) (Painting app with AI integrations)\n- [Kerlig AI](https://www.kerlig.com/) (AI writing assistant for macOS)\n- [AI Studio](https://github.com/MindWorkAI/AI-Studio)\n- [Sidellama](https://github.com/gyopak/sidellama) (browser-based LLM client)\n- [LLMStack](https://github.com/trypromptly/LLMStack) (No-code multi-agent framework to build LLM agents and workflows)\n- [BoltAI for Mac](https://boltai.com) (AI Chat Client for Mac)\n- [Harbor](https://github.com/av/harbor) (Containerized LLM Toolkit with Ollama as default backend)\n- [Go-CREW](https://www.jonathanhecl.com/go-crew/) (Powerful Offline RAG in Golang)\n- [PartCAD](https://github.com/openvmp/partcad/) (CAD model generation with OpenSCAD and CadQuery)\n- [Ollama4j Web UI](https://github.com/ollama4j/ollama4j-web-ui) - Java-based Web UI for Ollama built with Vaadin, Spring Boot and Ollama4j\n- [PyOllaMx](https://github.com/kspviswa/pyOllaMx) - macOS application capable of chatting with both Ollama and Apple MLX models.\n- [Claude Dev](https://github.com/saoudrizwan/claude-dev) - VSCode extension for multi-file/whole-repo coding\n- [Cherry Studio](https://github.com/kangfenmao/cherry-studio) (Desktop client with Ollama support)\n- [ConfiChat](https://github.com/1runeberg/confichat) (Lightweight, standalone, multi-platform, and privacy focused LLM chat interface with optional encryption)\n- [Archyve](https://github.com/nickthecook/archyve) (RAG-enabling document library)\n- [crewAI with Mesop](https://github.com/rapidarchitect/ollama-crew-mesop) (Mesop Web Interface to run crewAI with Ollama)\n\n### Terminal\n\n- [oterm](https://github.com/ggozad/oterm)\n- [Ellama Emacs client](https://github.com/s-kostyaev/ellama)\n- [Emacs client](https://github.com/zweifisch/ollama)\n- [gen.nvim](https://github.com/David-Kunz/gen.nvim)\n- [ollama.nvim](https://github.com/nomnivore/ollama.nvim)\n- [ollero.nvim](https://github.com/marco-souza/ollero.nvim)\n- [ollama-chat.nvim](https://github.com/gerazov/ollama-chat.nvim)\n- [ogpt.nvim](https://github.com/huynle/ogpt.nvim)\n- [gptel Emacs client](https://github.com/karthink/gptel)\n- [Oatmeal](https://github.com/dustinblackman/oatmeal)\n- [cmdh](https://github.com/pgibler/cmdh)\n- [ooo](https://github.com/npahlfer/ooo)\n- [shell-pilot](https://github.com/reid41/shell-pilot)\n- [tenere](https://github.com/pythops/tenere)\n- [llm-ollama](https://github.com/taketwo/llm-ollama) for [Datasette's LLM CLI](https://llm.datasette.io/en/stable/).\n- [typechat-cli](https://github.com/anaisbetts/typechat-cli)\n- [ShellOracle](https://github.com/djcopley/ShellOracle)\n- [tlm](https://github.com/yusufcanb/tlm)\n- [podman-ollama](https://github.com/ericcurtin/podman-ollama)\n- [gollama](https://github.com/sammcj/gollama)\n- [Ollama eBook Summary](https://github.com/cognitivetech/ollama-ebook-summary/)\n- [Ollama Mixture of Experts (MOE) in 50 lines of code](https://github.com/rapidarchitect/ollama_moe)\n\n### Apple Vision Pro\n- [Enchanted](https://github.com/AugustDev/enchanted)\n\n### Database\n\n- [MindsDB](https://github.com/mindsdb/mindsdb/blob/staging/mindsdb/integrations/handlers/ollama_handler/README.md) (Connects Ollama models with nearly 200 data platforms and apps)\n- [chromem-go](https://github.com/philippgille/chromem-go/blob/v0.5.0/embed_ollama.go) with [example](https://github.com/philippgille/chromem-go/tree/v0.5.0/examples/rag-wikipedia-ollama)\n\n### Package managers\n\n- [Pacman](https://archlinux.org/packages/extra/x86_64/ollama/)\n- [Gentoo](https://github.com/gentoo/guru/tree/master/app-misc/ollama)\n- [Helm Chart](https://artifacthub.io/packages/helm/ollama-helm/ollama)\n- [Guix channel](https://codeberg.org/tusharhero/ollama-guix)\n- [Nix package](https://search.nixos.org/packages?channel=24.05&show=ollama&from=0&size=50&sort=relevance&type=packages&query=ollama)\n- [Flox](https://flox.dev/blog/ollama-part-one)\n\n### Libraries\n\n- [LangChain](https://python.langchain.com/docs/integrations/llms/ollama) and [LangChain.js](https://js.langchain.com/docs/modules/model_io/models/llms/integrations/ollama) with [example](https://js.langchain.com/docs/use_cases/question_answering/local_retrieval_qa)\n- [Firebase Genkit](https://firebase.google.com/docs/genkit/plugins/ollama)\n- [crewAI](https://github.com/crewAIInc/crewAI)\n- [LangChainGo](https://github.com/tmc/langchaingo/) with [example](https://github.com/tmc/langchaingo/tree/main/examples/ollama-completion-example)\n- [LangChain4j](https://github.com/langchain4j/langchain4j) with [example](https://github.com/langchain4j/langchain4j-examples/tree/main/ollama-examples/src/main/java)\n- [LangChainRust](https://github.com/Abraxas-365/langchain-rust) with [example](https://github.com/Abraxas-365/langchain-rust/blob/main/examples/llm_ollama.rs)\n- [LlamaIndex](https://gpt-index.readthedocs.io/en/stable/examples/llm/ollama.html)\n- [LiteLLM](https://github.com/BerriAI/litellm)\n- [OllamaFarm for Go](https://github.com/presbrey/ollamafarm)\n- [OllamaSharp for .NET](https://github.com/awaescher/OllamaSharp)\n- [Ollama for Ruby](https://github.com/gbaptista/ollama-ai)\n- [Ollama-rs for Rust](https://github.com/pepperoni21/ollama-rs)\n- [Ollama-hpp for C++](https://github.com/jmont-dev/ollama-hpp)\n- [Ollama4j for Java](https://github.com/ollama4j/ollama4j)\n- [ModelFusion Typescript Library](https://modelfusion.dev/integration/model-provider/ollama)\n- [OllamaKit for Swift](https://github.com/kevinhermawan/OllamaKit)\n- [Ollama for Dart](https://github.com/breitburg/dart-ollama)\n- [Ollama for Laravel](https://github.com/cloudstudio/ollama-laravel)\n- [LangChainDart](https://github.com/davidmigloz/langchain_dart)\n- [Semantic Kernel - Python](https://github.com/microsoft/semantic-kernel/tree/main/python/semantic_kernel/connectors/ai/ollama)\n- [Haystack](https://github.com/deepset-ai/haystack-integrations/blob/main/integrations/ollama.md)\n- [Elixir LangChain](https://github.com/brainlid/langchain)\n- [Ollama for R - rollama](https://github.com/JBGruber/rollama)\n- [Ollama for R - ollama-r](https://github.com/hauselin/ollama-r)\n- [Ollama-ex for Elixir](https://github.com/lebrunel/ollama-ex)\n- [Ollama Connector for SAP ABAP](https://github.com/b-tocs/abap_btocs_ollama)\n- [Testcontainers](https://testcontainers.com/modules/ollama/)\n- [Portkey](https://portkey.ai/docs/welcome/integration-guides/ollama)\n- [PromptingTools.jl](https://github.com/svilupp/PromptingTools.jl) with an [example](https://svilupp.github.io/PromptingTools.jl/dev/examples/working_with_ollama)\n- [LlamaScript](https://github.com/Project-Llama/llamascript)\n- [Gollm](https://docs.gollm.co/examples/ollama-example)\n- [Ollamaclient for Golang](https://github.com/xyproto/ollamaclient)\n- [High-level function abstraction in Go](https://gitlab.com/tozd/go/fun)\n- [Ollama PHP](https://github.com/ArdaGnsrn/ollama-php)\n\n### Mobile\n\n- [Enchanted](https://github.com/AugustDev/enchanted)\n- [Maid](https://github.com/Mobile-Artificial-Intelligence/maid)\n- [ConfiChat](https://github.com/1runeberg/confichat) (Lightweight, standalone, multi-platform, and privacy focused LLM chat interface with optional encryption)\n\n### Extensions & Plugins\n\n- [Raycast extension](https://github.com/MassimilianoPasquini97/raycast_ollama)\n- [Discollama](https://github.com/mxyng/discollama) (Discord bot inside the Ollama discord channel)\n- [Continue](https://github.com/continuedev/continue)\n- [Obsidian Ollama plugin](https://github.com/hinterdupfinger/obsidian-ollama)\n- [Logseq Ollama plugin](https://github.com/omagdy7/ollama-logseq)\n- [NotesOllama](https://github.com/andersrex/notesollama) (Apple Notes Ollama plugin)\n- [Dagger Chatbot](https://github.com/samalba/dagger-chatbot)\n- [Discord AI Bot](https://github.com/mekb-turtle/discord-ai-bot)\n- [Ollama Telegram Bot](https://github.com/ruecat/ollama-telegram)\n- [Hass Ollama Conversation](https://github.com/ej52/hass-ollama-conversation)\n- [Rivet plugin](https://github.com/abrenneke/rivet-plugin-ollama)\n- [Obsidian BMO Chatbot plugin](https://github.com/longy2k/obsidian-bmo-chatbot)\n- [Cliobot](https://github.com/herval/cliobot) (Telegram bot with Ollama support)\n- [Copilot for Obsidian plugin](https://github.com/logancyang/obsidian-copilot)\n- [Obsidian Local GPT plugin](https://github.com/pfrankov/obsidian-local-gpt)\n- [Open Interpreter](https://docs.openinterpreter.com/language-model-setup/local-models/ollama)\n- [Llama Coder](https://github.com/ex3ndr/llama-coder) (Copilot alternative using Ollama)\n- [Ollama Copilot](https://github.com/bernardo-bruning/ollama-copilot) (Proxy that allows you to use ollama as a copilot like Github copilot)\n- [twinny](https://github.com/rjmacarthy/twinny) (Copilot and Copilot chat alternative using Ollama)\n- [Wingman-AI](https://github.com/RussellCanfield/wingman-ai) (Copilot code and chat alternative using Ollama and Hugging Face)\n- [Page Assist](https://github.com/n4ze3m/page-assist) (Chrome Extension)\n- [Plasmoid Ollama Control](https://github.com/imoize/plasmoid-ollamacontrol) (KDE Plasma extension that allows you to quickly manage/control Ollama model)\n- [AI Telegram Bot](https://github.com/tusharhero/aitelegrambot) (Telegram bot using Ollama in backend)\n- [AI ST Completion](https://github.com/yaroslavyaroslav/OpenAI-sublime-text) (Sublime Text 4 AI assistant plugin with Ollama support)\n- [Discord-Ollama Chat Bot](https://github.com/kevinthedang/discord-ollama) (Generalized TypeScript Discord Bot w/ Tuning Documentation)\n- [Discord AI chat/moderation bot](https://github.com/rapmd73/Companion) Chat/moderation bot written in python. Uses Ollama to create personalities.\n- [Headless Ollama](https://github.com/nischalj10/headless-ollama) (Scripts to automatically install ollama client & models on any OS for apps that depends on ollama server)\n- [vnc-lm](https://github.com/jk011ru/vnc-lm) (A containerized Discord bot with support for attachments and web links)\n- [LSP-AI](https://github.com/SilasMarvin/lsp-ai) (Open-source language server for AI-powered functionality)\n- [QodeAssist](https://github.com/Palm1r/QodeAssist) (AI-powered coding assistant plugin for Qt Creator)\n\n### Supported backends\n\n- [llama.cpp](https://github.com/ggerganov/llama.cpp) project founded by Georgi Gerganov.\n\n",
            "id": 40,
            "metadata": {
                "author": "Ollama",
                "shortDescription": "Get up and running with Llama 3.1, Mistral, Gemma 2, and other large language models.",
                "subTitle": "Get up and running with large language models"
            },
            "name": "ai/ollama",
            "project_id": 34,
            "pull_count": 1,
            "update_time": "2024-09-13 03:36:09.498000+00:00"
        },
        {
            "artifact_count": 1,
            "artifacts": [
                {
                    "accessories": null,
                    "addition_links": {
                        "build_history": {
                            "absolute": false,
                            "href": "/api/v2.0/projects/ai/repositories/anythingllm/artifacts/sha256:f3880aef297f1b56d562da632c6060473b9b03a2aa91cd9d1c7bad5469bb96c1/additions/build_history"
                        },
                        "vulnerabilities": {
                            "absolute": false,
                            "href": "/api/v2.0/projects/ai/repositories/anythingllm/artifacts/sha256:f3880aef297f1b56d562da632c6060473b9b03a2aa91cd9d1c7bad5469bb96c1/additions/vulnerabilities"
                        }
                    },
                    "annotations": null,
                    "digest": "sha256:f3880aef297f1b56d562da632c6060473b9b03a2aa91cd9d1c7bad5469bb96c1",
                    "extra_attrs": {
                        "architecture": "amd64",
                        "author": "",
                        "config": {
                            "Entrypoint": [
                                "/bin/bash",
                                "/usr/local/bin/docker-entrypoint.sh"
                            ],
                            "Env": [
                                "PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
                                "PUPPETEER_DOWNLOAD_BASE_URL=https://storage.googleapis.com/chrome-for-testing-public",
                                "NODE_ENV=production",
                                "ANYTHING_LLM_RUNTIME=docker"
                            ],
                            "Labels": {
                                "org.opencontainers.image.created": "2024-09-06T19:29:35.777Z",
                                "org.opencontainers.image.description": "The all-in-one Desktop & Docker AI application with full RAG and AI Agent capabilities.",
                                "org.opencontainers.image.licenses": "MIT",
                                "org.opencontainers.image.ref.name": "ubuntu",
                                "org.opencontainers.image.revision": "86f4466afbfb72f321e5aac84738a7b90c5cf901",
                                "org.opencontainers.image.source": "https://github.com/Mintplex-Labs/anything-llm",
                                "org.opencontainers.image.title": "anything-llm",
                                "org.opencontainers.image.url": "https://github.com/Mintplex-Labs/anything-llm",
                                "org.opencontainers.image.version": "master"
                            },
                            "User": "anythingllm",
                            "WorkingDir": "/app"
                        },
                        "created": "2024-09-06T19:32:57.708352217Z",
                        "os": "linux"
                    },
                    "icon": "sha256:0048162a053eef4d4ce3fe7518615bef084403614f8bca43b40ae2e762e11e06",
                    "id": 39,
                    "labels": null,
                    "manifest_media_type": "application/vnd.oci.image.manifest.v1+json",
                    "media_type": "application/vnd.oci.image.config.v1+json",
                    "project_id": 34,
                    "pull_time": "2024-09-10 08:04:41.473000+00:00",
                    "push_time": "2024-09-10 03:52:19.580000+00:00",
                    "references": null,
                    "repository_id": 39,
                    "scan_overview": null,
                    "size": 972948884,
                    "tags": [
                        {
                            "artifact_id": 39,
                            "id": 39,
                            "immutable": false,
                            "name": "latest",
                            "pull_time": "2024-09-10 08:04:41.473000+00:00",
                            "push_time": "2024-09-10 03:52:19.922000+00:00",
                            "repository_id": 39,
                            "signed": false
                        }
                    ],
                    "type": "IMAGE"
                }
            ],
            "build_history": [
                {
                    "created": "2024-06-27T20:10:10.528110614Z",
                    "created_by": "/bin/sh -c #(nop)  ARG RELEASE",
                    "empty_layer": true
                },
                {
                    "created": "2024-06-27T20:10:10.566300625Z",
                    "created_by": "/bin/sh -c #(nop)  ARG LAUNCHPAD_BUILD_ARCH",
                    "empty_layer": true
                },
                {
                    "created": "2024-06-27T20:10:10.606737029Z",
                    "created_by": "/bin/sh -c #(nop)  LABEL org.opencontainers.image.ref.name=ubuntu",
                    "empty_layer": true
                },
                {
                    "created": "2024-06-27T20:10:10.638915467Z",
                    "created_by": "/bin/sh -c #(nop)  LABEL org.opencontainers.image.version=22.04",
                    "empty_layer": true
                },
                {
                    "created": "2024-06-27T20:10:12.481980539Z",
                    "created_by": "/bin/sh -c #(nop) ADD file:d5da92199726e42da09a6f75a778befb607fe3f79e4afaf7ef5188329b26b386 in / "
                },
                {
                    "created": "2024-06-27T20:10:12.703519218Z",
                    "created_by": "/bin/sh -c #(nop)  CMD [\"/bin/bash\"]",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-09-06T18:41:07.567523674Z",
                    "created_by": "ARG ARG_UID=1000",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-09-06T18:41:07.567523674Z",
                    "created_by": "ARG ARG_GID=1000",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-09-06T18:41:07.567523674Z",
                    "created_by": "RUN |2 ARG_UID=1000 ARG_GID=1000 /bin/sh -c echo \"Preparing build of AnythingLLM image for non-ARM architecture\" # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-09-06T18:41:07.567523674Z",
                    "created_by": "SHELL [/bin/bash -o pipefail -c]",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-07-20T00:46:17.512445658Z",
                    "created_by": "RUN |2 ARG_UID=1000 ARG_GID=1000 /bin/bash -o pipefail -c DEBIAN_FRONTEND=noninteractive apt-get update &&     DEBIAN_FRONTEND=noninteractive apt-get install -yq --no-install-recommends         curl gnupg libgfortran5 libgbm1 tzdata netcat         libasound2 libatk1.0-0 libc6 libcairo2 libcups2 libdbus-1-3 libexpat1 libfontconfig1         libgcc1 libglib2.0-0 libgtk-3-0 libnspr4 libpango-1.0-0 libx11-6 libx11-xcb1 libxcb1         libxcomposite1 libxcursor1 libxdamage1 libxext6 libxfixes3 libxi6 libxrandr2 libxrender1         libxss1 libxtst6 ca-certificates fonts-liberation libappindicator1 libnss3 lsb-release         xdg-utils git build-essential ffmpeg &&     mkdir -p /etc/apt/keyrings &&     curl -fsSL https://deb.nodesource.com/gpgkey/nodesource-repo.gpg.key | gpg --dearmor -o /etc/apt/keyrings/nodesource.gpg &&     echo \"deb [signed-by=/etc/apt/keyrings/nodesource.gpg] https://deb.nodesource.com/node_18.x nodistro main\" | tee /etc/apt/sources.list.d/nodesource.list &&     apt-get update &&     apt-get install -yq --no-install-recommends nodejs &&     curl -LO https://github.com/yarnpkg/yarn/releases/download/v1.22.19/yarn_1.22.19_all.deb         && dpkg -i yarn_1.22.19_all.deb         && rm yarn_1.22.19_all.deb &&     apt-get clean &&     rm -rf /var/lib/apt/lists/* # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-07-20T00:46:17.81112833Z",
                    "created_by": "RUN |2 ARG_UID=1000 ARG_GID=1000 /bin/bash -o pipefail -c groupadd -g \"$ARG_GID\" anythingllm &&     useradd -l -u \"$ARG_UID\" -m -d /app -s /bin/bash -g anythingllm anythingllm &&     mkdir -p /app/frontend/ /app/server/ /app/collector/ && chown -R anythingllm:anythingllm /app # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-07-20T00:46:17.825123193Z",
                    "created_by": "COPY ./docker/docker-entrypoint.sh /usr/local/bin/ # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-07-20T00:46:17.904855343Z",
                    "created_by": "COPY ./docker/docker-healthcheck.sh /usr/local/bin/ # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-09-05T17:37:31.956143172Z",
                    "created_by": "COPY --chown=anythingllm:anythingllm ./docker/.env.example /app/server/.env # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-09-05T17:37:32.517124282Z",
                    "created_by": "RUN |2 ARG_UID=1000 ARG_GID=1000 /bin/bash -o pipefail -c chmod +x /usr/local/bin/docker-entrypoint.sh &&     chmod +x /usr/local/bin/docker-healthcheck.sh # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-09-06T18:41:07.567523674Z",
                    "created_by": "RUN |2 ARG_UID=1000 ARG_GID=1000 /bin/bash -o pipefail -c echo \"Running common build flow of AnythingLLM image for all architectures\" # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-09-06T18:41:07.567523674Z",
                    "created_by": "USER anythingllm",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-09-06T18:41:07.567523674Z",
                    "created_by": "WORKDIR /app"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-09-06T17:07:24.65226032Z",
                    "created_by": "COPY ./server /app/server/ # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-09-06T18:41:07.567523674Z",
                    "created_by": "WORKDIR /app/server"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-09-06T17:08:21.188636805Z",
                    "created_by": "RUN |2 ARG_UID=1000 ARG_GID=1000 /bin/bash -o pipefail -c yarn install --production --network-timeout 100000 && yarn cache clean # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-09-06T18:41:07.567523674Z",
                    "created_by": "WORKDIR /app"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-09-06T18:39:06.510110439Z",
                    "created_by": "COPY ./collector/ ./collector/ # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-09-06T18:41:07.567523674Z",
                    "created_by": "WORKDIR /app/collector"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-09-06T18:41:07.567523674Z",
                    "created_by": "ENV PUPPETEER_DOWNLOAD_BASE_URL=https://storage.googleapis.com/chrome-for-testing-public",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-09-06T18:39:32.944496238Z",
                    "created_by": "RUN |2 ARG_UID=1000 ARG_GID=1000 /bin/bash -o pipefail -c yarn install --production --network-timeout 100000 && yarn cache clean # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-09-06T18:39:32.944496238Z",
                    "created_by": "USER root",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-09-06T18:41:07.567523674Z",
                    "created_by": "WORKDIR /app/server"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-09-06T18:41:07.46092014Z",
                    "created_by": "RUN |2 ARG_UID=1000 ARG_GID=1000 /bin/bash -o pipefail -c npx --no node-llama-cpp download # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-09-06T18:41:07.567523674Z",
                    "created_by": "WORKDIR /app"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-09-06T18:41:07.567523674Z",
                    "created_by": "USER anythingllm",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-09-06T18:41:07.567523674Z",
                    "created_by": "WORKDIR /app"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-09-06T19:32:01.242441871Z",
                    "created_by": "COPY --chown=anythingllm:anythingllm /app/frontend/dist /app/server/public # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-09-06T19:32:01.242441871Z",
                    "created_by": "USER root",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-09-06T19:32:57.708352217Z",
                    "created_by": "RUN |2 ARG_UID=1000 ARG_GID=1000 /bin/bash -o pipefail -c chown -R anythingllm:anythingllm /app/server &&     chown -R anythingllm:anythingllm /app/collector # buildkit"
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-09-06T19:32:57.708352217Z",
                    "created_by": "USER anythingllm",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-09-06T19:32:57.708352217Z",
                    "created_by": "ENV NODE_ENV=production",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-09-06T19:32:57.708352217Z",
                    "created_by": "ENV ANYTHING_LLM_RUNTIME=docker",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-09-06T19:32:57.708352217Z",
                    "created_by": "HEALTHCHECK &{[\"CMD-SHELL\" \"/bin/bash /usr/local/bin/docker-healthcheck.sh || exit 1\"] \"1m0s\" \"10s\" \"1m0s\" \"0s\" '\\x00'}",
                    "empty_layer": true
                },
                {
                    "comment": "buildkit.dockerfile.v0",
                    "created": "2024-09-06T19:32:57.708352217Z",
                    "created_by": "ENTRYPOINT [\"/bin/bash\" \"/usr/local/bin/docker-entrypoint.sh\"]",
                    "empty_layer": true
                }
            ],
            "creation_time": "2024-09-10 03:52:19.149000+00:00",
            "description": "[author]: <> (Mintplex Labs Inc.)\n[subTitle]: <> (The all-in-one AI application)\n[shortDescription]: <> (The all-in-one Desktop & Docker AI application with built-in RAG, AI agents, and more.)\n\n<a name=\"readme-top\"></a>\n\n<p align=\"center\">\n  <a href=\"https://anythingllm.com\"><img src=\"https://github.com/Mintplex-Labs/anything-llm/blob/master/images/wordmark.png?raw=true\" alt=\"AnythingLLM logo\"></a>\n</p>\n\n<div align='center'>\n<a href=\"https://trendshift.io/repositories/2415\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/2415\" alt=\"Mintplex-Labs%2Fanything-llm | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n</div>\n\n<p align=\"center\">\n    <b>AnythingLLM:</b> The all-in-one AI app you were looking for.<br />\n    Chat with your docs, use AI Agents, hyper-configurable, multi-user, & no frustrating set up required.\n</p>\n\n<p align=\"center\">\n  <a href=\"https://discord.gg/6UyHPeGZAC\" target=\"_blank\">\n      <img src=\"https://img.shields.io/badge/chat-mintplex_labs-blue.svg?style=flat&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAMAAABEpIrGAAAAIGNIUk0AAHomAACAhAAA+gAAAIDoAAB1MAAA6mAAADqYAAAXcJy6UTwAAAH1UExURQAAAP////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////r6+ubn5+7u7/3+/v39/enq6urq6/v7+97f39rb26eoqT1BQ0pOT4+Rkuzs7cnKykZKS0NHSHl8fdzd3ejo6UxPUUBDRdzc3RwgIh8jJSAkJm5xcvHx8aanqB4iJFBTVezt7V5hYlJVVuLj43p9fiImKCMnKZKUlaaoqSElJ21wcfT09O3u7uvr6zE0Nr6/wCUpK5qcnf7+/nh7fEdKTHx+f0tPUOTl5aipqiouMGtubz5CRDQ4OsTGxufn515hY7a3uH1/gXBydIOFhlVYWvX29qaoqCQoKs7Pz/Pz87/AwUtOUNfY2dHR0mhrbOvr7E5RUy8zNXR2d/f39+Xl5UZJSx0hIzQ3Odra2/z8/GlsbaGjpERHSezs7L/BwScrLTQ4Odna2zM3Obm7u3x/gKSmp9jZ2T1AQu/v71pdXkVISr2+vygsLiInKTg7PaOlpisvMcXGxzk8PldaXPLy8u7u7rm6u7S1tsDBwvj4+MPExbe4ueXm5s/Q0Kyf7ewAAAAodFJOUwAABClsrNjx/QM2l9/7lhmI6jTB/kA1GgKJN+nea6vy/MLZQYeVKK3rVA5tAAAAAWJLR0QB/wIt3gAAAAd0SU1FB+cKBAAmMZBHjXIAAAISSURBVDjLY2CAAkYmZhZWNnYODnY2VhZmJkYGVMDIycXNw6sBBbw8fFycyEoYGfkFBDVQgKAAPyMjQl5IWEQDDYgIC8FUMDKKsmlgAWyiEBWMjGJY5YEqxMAqGMWFNXAAYXGgAkYJSQ2cQFKCkYFRShq3AmkpRgYJbghbU0tbB0Tr6ukbgGhDI10gySfBwCwDUWBsYmpmDqQtLK2sbTQ0bO3sHYA8GWYGWWj4WTs6Obu4ami4OTm7exhqeHp5+4DCVJZBDmqdr7ufn3+ArkZgkJ+fU3CIRmgYWFiOARYGvo5OQUHhEUAFTkF+kVHRsLBgkIeyYmLjwoOc4hMSk5JTnINS06DC8gwcEEZ6RqZGlpOfc3ZObl5+gZ+TR2ERWFyBQQFMF5eklmqUpQb5+ReU61ZUOvkFVVXXQBSAraitq29o1GiKcfLzc29u0mjxBzq0tQ0kww5xZHtHUGeXhkZhdxBYgZ4d0LI6c4gjwd7siQQraOp1AivQ6CuAKZCDBBRQQQNQgUb/BGf3cqCCiZOcnCe3QQIKHNRTpk6bDgpZjRkzg3pBQTBrdtCcuZCgluAD0vPmL1gIdvSixUuWgqNs2YJ+DUhkEYxuggkGmOQUcckrioPTJCOXEnZ5JS5YslbGnuyVERlDDFvGEUPOWvwqaH6RVkHKeuDMK6SKnHlVhTgx8jeTmqy6Eij7K6nLqiGyPwChsa1MUrnq1wAAACV0RVh0ZGF0ZTpjcmVhdGUAMjAyMy0xMC0wNFQwMDozODo0OSswMDowMB9V0a8AAAAldEVYdGRhdGU6bW9kaWZ5ADIwMjMtMTAtMDRUMDA6Mzg6NDkrMDA6MDBuCGkTAAAAKHRFWHRkYXRlOnRpbWVzdGFtcAAyMDIzLTEwLTA0VDAwOjM4OjQ5KzAwOjAwOR1IzAAAAABJRU5ErkJggg==\" alt=\"Discord\">\n  </a> |\n  <a href=\"https://github.com/Mintplex-Labs/anything-llm/blob/master/LICENSE\" target=\"_blank\">\n      <img src=\"https://img.shields.io/static/v1?label=license&message=MIT&color=white\" alt=\"License\">\n  </a> |\n  <a href=\"https://docs.anythingllm.com\" target=\"_blank\">\n    Docs\n  </a> |\n   <a href=\"https://my.mintplexlabs.com/aio-checkout?product=anythingllm\" target=\"_blank\">\n    Hosted Instance\n  </a>\n</p>\n\n<p align=\"center\">\n  <b>English</b> \u00b7 <a href='./locales/README.zh-CN.md'>\u7b80\u4f53\u4e2d\u6587</a> \u00b7 <a href='./locales/README.ja-JP.md'>\u65e5\u672c\u8a9e</a>\n</p>\n\n<p align=\"center\">\n\ud83d\udc49 AnythingLLM for desktop (Mac, Windows, & Linux)! <a href=\"https://anythingllm.com/download\" target=\"_blank\"> Download Now</a>\n</p>\n\nA full-stack application that enables you to turn any document, resource, or piece of content into context that any LLM can use as references during chatting. This application allows you to pick and choose which LLM or Vector Database you want to use as well as supporting multi-user management and permissions.\n\n![Chatting](https://github.com/Mintplex-Labs/anything-llm/assets/16845892/cfc5f47c-bd91-4067-986c-f3f49621a859)\n\n<details>\n<summary><kbd>Watch the demo!</kbd></summary>\n\n[![Watch the video](/images/youtube.png)](https://youtu.be/f95rGD9trL0)\n\n</details>\n\n### Product Overview\n\nAnythingLLM is a full-stack application where you can use commercial off-the-shelf LLMs or popular open source LLMs and vectorDB solutions to build a private ChatGPT with no compromises that you can run locally as well as host remotely and be able to chat intelligently with any documents you provide it.\n\nAnythingLLM divides your documents into objects called `workspaces`. A Workspace functions a lot like a thread, but with the addition of containerization of your documents. Workspaces can share documents, but they do not talk to each other so you can keep your context for each workspace clean.\n\n## Cool features of AnythingLLM\n\n- \ud83c\udd95 **Multi-modal support (both closed and open-source LLMs!)**\n- \ud83d\udc64 Multi-user instance support and permissioning _Docker version only_\n- \ud83e\uddbe Agents inside your workspace (browse the web, run code, etc)\n- \ud83d\udcac [Custom Embeddable Chat widget for your website](./embed/README.md) _Docker version only_\n- \ud83d\udcd6 Multiple document type support (PDF, TXT, DOCX, etc)\n- Simple chat UI with Drag-n-Drop funcitonality and clear citations.\n- 100% Cloud deployment ready.\n- Works with all popular [closed and open-source LLM providers](#supported-llms-embedder-models-speech-models-and-vector-databases).\n- Built-in cost & time-saving measures for managing very large documents compared to any other chat UI.\n- Full Developer API for custom integrations!\n- Much more...install and find out!\n\n### Supported LLMs, Embedder Models, Speech models, and Vector Databases\n\n**Large Language Models (LLMs):**\n\n- [Any open-source llama.cpp compatible model](/server/storage/models/README.md#text-generation-llm-selection)\n- [OpenAI](https://openai.com)\n- [OpenAI (Generic)](https://openai.com)\n- [Azure OpenAI](https://azure.microsoft.com/en-us/products/ai-services/openai-service)\n- [AWS Bedrock](https://aws.amazon.com/bedrock/)\n- [Anthropic](https://www.anthropic.com/)\n- [Google Gemini Pro](https://ai.google.dev/)\n- [Hugging Face (chat models)](https://huggingface.co/)\n- [Ollama (chat models)](https://ollama.ai/)\n- [LM Studio (all models)](https://lmstudio.ai)\n- [LocalAi (all models)](https://localai.io/)\n- [Together AI (chat models)](https://www.together.ai/)\n- [Perplexity (chat models)](https://www.perplexity.ai/)\n- [OpenRouter (chat models)](https://openrouter.ai/)\n- [Mistral](https://mistral.ai/)\n- [Groq](https://groq.com/)\n- [Cohere](https://cohere.com/)\n- [KoboldCPP](https://github.com/LostRuins/koboldcpp)\n- [LiteLLM](https://github.com/BerriAI/litellm)\n- [Text Generation Web UI](https://github.com/oobabooga/text-generation-webui)\n\n**Embedder models:**\n\n- [AnythingLLM Native Embedder](/server/storage/models/README.md) (default)\n- [OpenAI](https://openai.com)\n- [Azure OpenAI](https://azure.microsoft.com/en-us/products/ai-services/openai-service)\n- [LocalAi (all)](https://localai.io/)\n- [Ollama (all)](https://ollama.ai/)\n- [LM Studio (all)](https://lmstudio.ai)\n- [Cohere](https://cohere.com/)\n\n**Audio Transcription models:**\n\n- [AnythingLLM Built-in](https://github.com/Mintplex-Labs/anything-llm/tree/master/server/storage/models#audiovideo-transcription) (default)\n- [OpenAI](https://openai.com/)\n\n**TTS (text-to-speech) support:**\n\n- Native Browser Built-in (default)\n- [PiperTTSLocal - runs in browser](https://github.com/rhasspy/piper)\n- [OpenAI TTS](https://platform.openai.com/docs/guides/text-to-speech/voice-options)\n- [ElevenLabs](https://elevenlabs.io/)\n\n**STT (speech-to-text) support:**\n\n- Native Browser Built-in (default)\n\n**Vector Databases:**\n\n- [LanceDB](https://github.com/lancedb/lancedb) (default)\n- [Astra DB](https://www.datastax.com/products/datastax-astra)\n- [Pinecone](https://pinecone.io)\n- [Chroma](https://trychroma.com)\n- [Weaviate](https://weaviate.io)\n- [Qdrant](https://qdrant.tech)\n- [Milvus](https://milvus.io)\n- [Zilliz](https://zilliz.com)\n\n### Technical Overview\n\nThis monorepo consists of three main sections:\n\n- `frontend`: A viteJS + React frontend that you can run to easily create and manage all your content the LLM can use.\n- `server`: A NodeJS express server to handle all the interactions and do all the vectorDB management and LLM interactions.\n- `collector`: NodeJS express server that process and parses documents from the UI.\n- `docker`: Docker instructions and build process + information for building from source.\n- `embed`: Submodule for generation & creation of the [web embed widget](https://github.com/Mintplex-Labs/anythingllm-embed).\n- `browser-extension`: Submodule for the [chrome browser extension](https://github.com/Mintplex-Labs/anythingllm-extension).\n\n## \ud83d\udef3 Self Hosting\n\nMintplex Labs & the community maintain a number of deployment methods, scripts, and templates that you can use to run AnythingLLM locally. Refer to the table below to read how to deploy on your preferred environment or to automatically deploy.\n| Docker | AWS | GCP | Digital Ocean | Render.com |\n|----------------------------------------|----:|-----|---------------|------------|\n| [![Deploy on Docker][docker-btn]][docker-deploy] | [![Deploy on AWS][aws-btn]][aws-deploy] | [![Deploy on GCP][gcp-btn]][gcp-deploy] | [![Deploy on DigitalOcean][do-btn]][do-deploy] | [![Deploy on Render.com][render-btn]][render-deploy] |\n\n| Railway  |  RepoCloud | Elestio |\n| --- | --- | --- |\n| [![Deploy on Railway][railway-btn]][railway-deploy] | [![Deploy on RepoCloud][repocloud-btn]][repocloud-deploy] | [![Deploy on Elestio][elestio-btn]][elestio-deploy] |\n\n[or set up a production AnythingLLM instance without Docker \u2192](./BARE_METAL.md)\n\n## How to setup for development\n\n- `yarn setup` To fill in the required `.env` files you'll need in each of the application sections (from root of repo).\n  - Go fill those out before proceeding. Ensure `server/.env.development` is filled or else things won't work right.\n- `yarn dev:server` To boot the server locally (from root of repo).\n- `yarn dev:frontend` To boot the frontend locally (from root of repo).\n- `yarn dev:collector` To then run the document collector (from root of repo).\n\n[Learn about documents](./server/storage/documents/DOCUMENTS.md)\n\n[Learn about vector caching](./server/storage/vector-cache/VECTOR_CACHE.md)\n\n## Telemetry & Privacy\n\nAnythingLLM by Mintplex Labs Inc contains a telemetry feature that collects anonymous usage information.\n\n<details>\n<summary><kbd>More about Telemetry & Privacy for AnythingLLM</kbd></summary>\n\n### Why?\n\nWe use this information to help us understand how AnythingLLM is used, to help us prioritize work on new features and bug fixes, and to help us improve AnythingLLM's performance and stability.\n\n### Opting out\n\nSet `DISABLE_TELEMETRY` in your server or docker .env settings to \"true\" to opt out of telemetry. You can also do this in-app by going to the sidebar > `Privacy` and disabling telemetry.\n\n### What do you explicitly track?\n\nWe will only track usage details that help us make product and roadmap decisions, specifically:\n\n- Typ of your installation (Docker or Desktop)\n- When a document is added or removed. No information _about_ the document. Just that the event occurred. This gives us an idea of use.\n- Type of vector database in use. Let's us know which vector database provider is the most used to prioritize changes when updates arrive for that provider.\n- Type of LLM in use. Let's us know the most popular choice and prioritize changes when updates arrive for that provider.\n- Chat is sent. This is the most regular \"event\" and gives us an idea of the daily-activity of this project across all installations. Again, only the event is sent - we have no information on the nature or content of the chat itself.\n\nYou can verify these claims by finding all locations `Telemetry.sendTelemetry` is called. Additionally these events are written to the output log so you can also see the specific data which was sent - if enabled. No IP or other identifying information is collected. The Telemetry provider is [PostHog](https://posthog.com/) - an open-source telemetry collection service.\n\n[View all telemetry events in source code](https://github.com/search?q=repo%3AMintplex-Labs%2Fanything-llm%20.sendTelemetry\\(&type=code)\n\n</details>\n\n\n## \ud83d\udc4b Contributing\n\n- create issue\n- create PR with branch name format of `<issue number>-<short name>`\n- LGTM from core-team\n\n## \ud83c\udf1f Contributors\n\n[![anythingllm contributors](https://contrib.rocks/image?repo=mintplex-labs/anything-llm)](https://github.com/mintplex-labs/anything-llm/graphs/contributors)\n\n[![Star History Chart](https://api.star-history.com/svg?repos=mintplex-labs/anything-llm&type=Timeline)](https://star-history.com/#mintplex-labs/anything-llm&Date)\n\n## \ud83d\udd17 More Products\n\n- **[VectorAdmin][vector-admin]:** An all-in-one GUI & tool-suite for managing vector databases.\n- **[OpenAI Assistant Swarm][assistant-swarm]:** Turn your entire library of OpenAI assistants into one single army commanded from a single agent.\n\n<div align=\"right\">\n\n[![][back-to-top]](#readme-top)\n\n</div>\n\n---\n\nCopyright \u00a9 2024 [Mintplex Labs][profile-link]. <br />\nThis project is [MIT](./LICENSE) licensed.\n\n<!-- LINK GROUP -->\n\n[back-to-top]: https://img.shields.io/badge/-BACK_TO_TOP-222628?style=flat-square\n[profile-link]: https://github.com/mintplex-labs\n[vector-admin]: https://github.com/mintplex-labs/vector-admin\n[assistant-swarm]: https://github.com/Mintplex-Labs/openai-assistant-swarm\n[docker-btn]: ./images/deployBtns/docker.png\n[docker-deploy]: ./docker/HOW_TO_USE_DOCKER.md\n[aws-btn]: ./images/deployBtns/aws.png\n[aws-deploy]: ./cloud-deployments/aws/cloudformation/DEPLOY.md\n[gcp-btn]: https://deploy.cloud.run/button.svg\n[gcp-deploy]: ./cloud-deployments/gcp/deployment/DEPLOY.md\n[do-btn]: https://www.deploytodo.com/do-btn-blue.svg\n[do-deploy]: ./cloud-deployments/digitalocean/terraform/DEPLOY.md\n[render-btn]: https://render.com/images/deploy-to-render-button.svg\n[render-deploy]: https://render.com/deploy?repo=https://github.com/Mintplex-Labs/anything-llm&branch=render\n[render-btn]: https://render.com/images/deploy-to-render-button.svg\n[render-deploy]: https://render.com/deploy?repo=https://github.com/Mintplex-Labs/anything-llm&branch=render\n[railway-btn]: https://railway.app/button.svg\n[railway-deploy]: https://railway.app/template/HNSCS1?referralCode=WFgJkn\n[repocloud-btn]: https://d16t0pc4846x52.cloudfront.net/deploylobe.svg\n[repocloud-deploy]: https://repocloud.io/details/?app_id=276\n[elestio-btn]: https://elest.io/images/logos/deploy-to-elestio-btn.png\n[elestio-deploy]: https://elest.io/open-source/anythingllm\n",
            "id": 39,
            "metadata": {
                "assistant-swarm": "https://github.com/Mintplex-Labs/openai-assistant-swar",
                "author": "Mintplex Labs Inc.",
                "aws-btn": "images/deployBtns/aws.pn",
                "aws-deploy": "cloud-deployments/aws/cloudformation/DEPLOY.m",
                "back-to-top": "https://img.shields.io/badge/-BACK_TO_TOP-222628?style=flat-squar",
                "do-btn": "https://www.deploytodo.com/do-btn-blue.sv",
                "do-deploy": "cloud-deployments/digitalocean/terraform/DEPLOY.m",
                "docker-btn": "images/deployBtns/docker.pn",
                "docker-deploy": "docker/HOW_TO_USE_DOCKER.m",
                "elestio-btn": "https://elest.io/images/logos/deploy-to-elestio-btn.pn",
                "elestio-deploy": "https://elest.io/open-source/anythingll",
                "gcp-btn": "https://deploy.cloud.run/button.sv",
                "gcp-deploy": "cloud-deployments/gcp/deployment/DEPLOY.m",
                "profile-link": "https://github.com/mintplex-lab",
                "railway-btn": "https://railway.app/button.sv",
                "railway-deploy": "https://railway.app/template/HNSCS1?referralCode=WFgJk",
                "render-btn": "https://render.com/images/deploy-to-render-button.sv",
                "render-deploy": "https://render.com/deploy?repo=https://github.com/Mintplex-Labs/anything-llm&branch=rende",
                "repocloud-btn": "https://d16t0pc4846x52.cloudfront.net/deploylobe.sv",
                "repocloud-deploy": "https://repocloud.io/details/?app_id=27",
                "shortDescription": "The all-in-one Desktop & Docker AI application with built-in RAG, AI agents, and more.",
                "subTitle": "The all-in-one AI application",
                "vector-admin": "https://github.com/mintplex-labs/vector-admi"
            },
            "name": "ai/anythingllm",
            "project_id": 34,
            "pull_count": 1,
            "update_time": "2024-09-13 03:39:22.110000+00:00"
        }
    ],
    "togglable": null,
    "update_time": "2024-09-10 03:38:36.774000+00:00"
}